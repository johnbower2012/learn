{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Here I've coded an artificial neural network with an arbitrary number of layers. The ANN is encoded in a class, and is fed a dictionary of your choices for activation functions and loss functions, as well as a list of the neurons in each layer, for example a two layer network with 100 and 50, respectively, is fed as [100,50].\n",
    "\n",
    "Then, the easiest way to search for effective parameters sets is to use RunOne or RunTwo. RunOne will train a one layer NN across the list of options you feed it, then test its accuracy. For example, [10,20,30] will train with 10 neurons, 20 neurons, 30 neurons, and spit out the accuracy for each. Similarly, RunTwo trains in a list of two lists, the first for the number of neurons in the first layer and the second for the second layer. It will train across all combinations and sit out a matrix of accuracies.\n",
    "\n",
    "Then, once you've identified a good parameter set, use the solitary Train function grouped with RunOne and RunTwo in order to train one a specific parameter set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def read_dataset(feature_file, label_file):\n",
    "    ''' Read data set in *.csv to data frame in Pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (features)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def normalize_features(X_train, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler #import libaray\n",
    "    scaler = StandardScaler() # call an object function\n",
    "    scaler.fit(X_train) # calculate mean, std in X_train\n",
    "    X_train_norm = scaler.transform(X_train) # apply normalization on X_train\n",
    "    X_test_norm = scaler.transform(X_test) # we use the same normalization on X_test\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "\n",
    "def one_hot_encoder(y_train, y_test):\n",
    "    ''' convert label to a vector under one-hot-code fashion '''\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    y_train_ohe = lb.transform(y_train)\n",
    "    y_test_ohe = lb.transform(y_test)\n",
    "    return y_train_ohe, y_test_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "X_train_digits, y_train_digits = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test_digits, y_test_digits = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "X_train_norm_digits, X_test_norm_digits = normalize_features(X_train_digits, X_test_digits)\n",
    "y_train_ohe_digits, y_test_ohe_digits = one_hot_encoder(y_train_digits, y_test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW IS TESTING! DIVE IN; THE WATER'S FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFilter:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"convolution\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_filt = info.dimensions[0]\n",
    "        self.num_ch = info.dimensions[1]\n",
    "        self.f_i = info.dimensions[2]\n",
    "        self.f_j = info.dimensions[3]\n",
    "        self.weight = self.FInitializeFilter()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j\n",
    "        self.activation = info.activation        \n",
    "    def FInitializeFilter(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.dimensions))),size=self.dimensions)\n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.num_filt))),size=(1,self.num_filt))\n",
    "    \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.f_i)/self.stride_i) + 1)\n",
    "        out_j = int(np.ceil((imag_j - self.f_j)/self.stride_j) + 1)\n",
    "        z = np.zeros((num_imag, self.num_filt, out_i, out_j))\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                f_y_end = self.f_j\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y\n",
    "                    f_x_end = self.f_i\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x\n",
    "                        z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*self.weight[curr_f,:,0:f_x_end,0:f_y_end]) + self.bias[0][curr_f]\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,imag_in):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag,num_ch,imag_i,imag_j))\n",
    "        dfilt = np.zeros(self.weight.shape)\n",
    "        dbias = np.zeros((1,self.num_filt))\n",
    "\n",
    "        for i in range(imag_in.shape[0]):\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = out_y = 0\n",
    "                f_y_end = self.f_i\n",
    "                while(curr_y + self.f_j < imag_j + 1):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y + 1\n",
    "                    f_x_end = self.f_j\n",
    "                    while(curr_x + self.f_i < imag_i + 1): \n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x + 1                      \n",
    "                        dout[i,:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[i,curr_f, out_x, out_y] * self.weight[curr_f,:,:f_x_end,:f_y_end]\n",
    "                        dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[i,curr_f,out_x,out_y] * imag_in[i,:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "                dbias[0][curr_f] += np.sum(dprev[i,curr_f])\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('imag_in\\n',imag_in) \n",
    "        print('dfilt\\n',dfilt)\n",
    "        print('dbias\\n',dbias)\n",
    "        '''\n",
    "        return dout,dfilt,dbias\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Filter Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  num_filt:\",self.num_filt)\n",
    "        print(\"  num_ch:\",self.num_ch)\n",
    "        print(\"  f_i:\",self.f_i)\n",
    "        print(\"  f_j:\",self.f_j)\n",
    "        print(\"  stride_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "        #print(\"  act.f:\",self.activation.f)\n",
    "        #print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  filt:\\n\",self.weight)\n",
    "        print(\"  bias:\\n\",self.bias)\n",
    "\n",
    "class CPool:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"pool\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_ch = info.dimensions[0]\n",
    "        self.pool_i = info.dimensions[1]\n",
    "        self.pool_j = info.dimensions[2]\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j  \n",
    "        \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the pool does not match the number of channels in the input!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.pool_i)/self.stride_i)) + 1\n",
    "        out_j = int(np.ceil((imag_j - self.pool_j)/self.stride_j)) + 1\n",
    "        z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_chan in range(self.num_ch):\n",
    "                curr_y = out_y = 0\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        current_y_end = imag_j\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan, curr_x:curr_x_end, curr_y:curr_y_end])\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,z\n",
    "\n",
    "    def FFeedBack(self, dprev, imag_in):\n",
    "        (num_imag_p, num_ch_p, dp_i, dp_j) = dprev.shape\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(num_ch_p != num_ch):\n",
    "            print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag, num_ch,imag_i,imag_j))\n",
    "        for i in range(imag_in.shape[0]):\n",
    "            for curr_ch in range(num_ch):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                while(out_y < dp_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                    while(out_x < dp_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        (a,b) = np.unravel_index(np.nanargmax(imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                        dout[i,curr_ch,curr_x+a,curr_y+b] += dprev[i,curr_ch,out_x,out_y]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('imag_in\\n',imag_in)\n",
    "        '''\n",
    "        return dout\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Pool Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  pool_i:\",self.pool_i)\n",
    "        print(\"  pool_j:\",self.pool_j)\n",
    "        print(\"  stide_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "\n",
    "class CConnection:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"connection\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.neurons_in = info.dimensions[0]\n",
    "        self.neurons_out = info.dimensions[1]\n",
    "        self.weight = self.FInitializeWeights()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.activation = info.activation\n",
    "   \n",
    "    def FInitializeWeights(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod([self.neurons_in,self.neurons_out]))),size=[self.neurons_in,self.neurons_out])\n",
    "       \n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.neurons_out))),size=(1,self.neurons_out))\n",
    "\n",
    "    def FFeedForward(self,images):\n",
    "        z = images.dot(self.weight) + self.bias\n",
    "        return z, self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,data_in):\n",
    "        dW = self.activation.f(data_in).T.dot(dprev)\n",
    "        db = np.sum(dprev,axis=0,keepdims=True)\n",
    "        dout = dprev.dot(self.weight.T)*self.activation.d(data_in)\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('f(data)\\n',self.activation.f(data_in))\n",
    "        print('d(data)\\n',self.activation.d(data_in))\n",
    "        print('weight\\n',self.weight)\n",
    "        print('bias\\n',self.bias)\n",
    "        print('dW\\n',dW)\n",
    "        print('db\\n',db)\n",
    "        '''\n",
    "        return dout, dW, db\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Connection Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  neurons_in:\",self.neurons_in)\n",
    "        print(\"  neurons_out:\",self.neurons_out)\n",
    "        #print(\"  act.f:\",self.activation.f)\n",
    "        #print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  weights:\\n\",self.weight)\n",
    "        print(\"  bias:\\n\",self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLinear(X):\n",
    "    return X\n",
    "def FRELU(X):\n",
    "    a = np.copy(X)\n",
    "    a[X<0]=0\n",
    "    return a\n",
    "def FRELU_dx(X):\n",
    "    dx = np.zeros(X.shape)\n",
    "    dx[X>0] = 1\n",
    "    return dx\n",
    "\n",
    "def RegularizedLoss(y,yhat,regularization_parameter,C):\n",
    "    loss = 0\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    hinge[hinge<0]=0\n",
    "    loss = np.sum(hinge)\n",
    "    loss *= regularization_parameter\n",
    "    temp = 0\n",
    "    for item in C:\n",
    "        for elem in item:\n",
    "            temp += np.sum(elem*elem)\n",
    "    return loss + np.sqrt(temp)\n",
    "\n",
    "def RegularizedLoss_dx(y,yhat,regularization_parameter):\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "    loss = np.zeros(y.shape)\n",
    "    for i in range(hinge.shape[0]):\n",
    "        if(hinge[i]>0):\n",
    "            loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "    loss *= regularization_parameter\n",
    "    return loss\n",
    "\n",
    "def softmax(z):\n",
    "    exp_value = np.exp(z-np.amax(z, axis=1, keepdims=True)) # for stablility\n",
    "    # keepdims = True means that the output's dimension is the same as of z\n",
    "    softmax_scores = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
    "    return softmax_scores\n",
    "def accuracy(ypred, yexact):\n",
    "    p = np.array(ypred == yexact, dtype = int)\n",
    "    return np.sum(p)/float(len(yexact))\n",
    "\n",
    "class CActivation:\n",
    "    def __init__(self,Function,Derivative):\n",
    "        self.f = Function\n",
    "        self.d = Derivative\n",
    "\n",
    "RELU  = CActivation(FRELU,FRELU_dx)\n",
    "class CLayer:\n",
    "    def __init__(self,Tag,Info):\n",
    "        self.tag = Tag\n",
    "        self.info = Info\n",
    "        self.indim = None\n",
    "        self.outdim = None\n",
    "        \n",
    "class CInfo:\n",
    "    def __init__(self,dimensions=None,stride_i=1,stride_j=1,activation=RELU):\n",
    "        self.dimensions = dimensions\n",
    "        self.stride_i = stride_i\n",
    "        self.stride_j = stride_j\n",
    "        self.activation = activation\n",
    "    def FAddDimensions(self,Dimensions):\n",
    "        self.dimensions = Dimensions\n",
    "    def FAddStride(self,Stride_i=1,Stride_j=1):\n",
    "        self.stride_i = Stride_i\n",
    "        self.stride_j = Stride_j\n",
    "    def FAddActivation(self,Activation):\n",
    "        self.activation = Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, indim, outdim, LayersInfo, lr=0.1, rp=0.1):\n",
    "        self.in_ch = []\n",
    "        self.indim_i = []\n",
    "        self.indim_j = []\n",
    "        self.in_ch.append(indim[0])\n",
    "        self.indim_i.append(indim[1])\n",
    "        self.indim_j.append(indim[1])\n",
    "        self.outdim = outdim\n",
    "\n",
    "        #self.X = X\n",
    "        #self.X_reshape = self.X.reshape(self.samples,self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        #self.y = y\n",
    "        self.lr = lr\n",
    "        self.rp = rp\n",
    "        self.probability = softmax\n",
    "\n",
    "        self.layer = []\n",
    "        for Layer in LayersInfo:\n",
    "            self.layer.append(self.FAddLayer(Layer))\n",
    "        outinfo = CInfo([-1,self.outdim])\n",
    "        finallayer = CLayer('connection',outinfo)\n",
    "        self.layer.append(self.FAddLayer(finallayer))\n",
    "            \n",
    "\n",
    "    def FAddLayer(self,Layer):\n",
    "        if(Layer.tag=='convolution'):\n",
    "            Layer.info.dimensions[1] = self.in_ch[-1]\n",
    "            self.in_ch.append(Layer.info.dimensions[0])\n",
    "            f_i = Layer.info.dimensions[2]\n",
    "            f_j = Layer.info.dimensions[3]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.indim_i.append(int(np.ceil((indim_i - f_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - f_j)/stride_j) + 1))\n",
    "            return CFilter(Layer.info)\n",
    "        elif(Layer.tag=='pool'):\n",
    "            Layer.info.dimensions[0] = self.in_ch[-1]\n",
    "            p_i = Layer.info.dimensions[1]\n",
    "            p_j = Layer.info.dimensions[2]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.in_ch.append(self.in_ch[-1])\n",
    "            self.indim_i.append(int(np.ceil((indim_i - p_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - p_j)/stride_j) + 1))\n",
    "            return CPool(Layer.info)\n",
    "        elif(Layer.tag=='connection'):\n",
    "            flatten = self.in_ch[-1]*self.indim_i[-1]*self.indim_j[-1]\n",
    "            Layer.info.dimensions[0] = flatten\n",
    "            self.in_ch.append(1)\n",
    "            self.indim_i.append(1)\n",
    "            self.indim_j.append(Layer.info.dimensions[1])\n",
    "            return CConnection(Layer.info)\n",
    "        else:\n",
    "            print(Layer.tag,'is not a valid layer option. Double check initialization.')\n",
    "            return None\n",
    "\n",
    "    def FPrint(self):\n",
    "        for l in self.layer:\n",
    "            l.FPrint()\n",
    "\n",
    "    def FFeedForward(self,X):\n",
    "        self.z = []\n",
    "        self.f = []\n",
    "        images = X.reshape(X.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        self.f.append(images)\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            self.z.append(Z)\n",
    "            if(i != len(self.layer) -1):\n",
    "                self.f.append(F)\n",
    "            images = self.f[-1]\n",
    "            '''\n",
    "            print('')\n",
    "            print(self.layer[i].FPrint())\n",
    "            print('z',Z)\n",
    "            print('f',F)\n",
    "            '''\n",
    "        self.yhat = self.probability(self.z[-1])\n",
    "        \n",
    "    def FBackPropagation(self,y):\n",
    "        d = []\n",
    "        d.insert(0,self.Loss_dx(y,self.yhat)) \n",
    "        #print('dout\\n',d[0])\n",
    "        for i in range(len(self.layer)):\n",
    "            images = self.f[-1-i]\n",
    "            if(self.layer[-1-i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            elif(self.layer[-1-i+1].tag == 'connection'):\n",
    "                d[0] = np.reshape(d[0],(images.shape[0],self.in_ch[-1-i],self.indim_i[-1-i],self.indim_j[-1-i]))\n",
    "            if(self.layer[-1-i].tag != 'pool'):\n",
    "                dout,dW,db = self.layer[-1-i].FFeedBack(d[0],images)\n",
    "                #dW /= float(len(y))\n",
    "                #db /= float(len(y))\n",
    "                self.layer[-1-i].weight = self.layer[-1-i].weight - self.lr*dW\n",
    "                if(self.rp != 0 and self.layer[-1-i].weight.all() !=0 ):\n",
    "                    self.layer[-1-i].weight = self.layer[-1-i].weight - self.rp*self.layer[-1-i].weight/np.sqrt(np.sum(self.layer[-1-i].weight*self.layer[-1-i].weight))/self.layer[-1-i].weight.size\n",
    "\n",
    "                self.layer[-1-i].bias = self.layer[-1-i].bias - self.lr*db\n",
    "                if(self.rp != 0 and self.layer[-1-i].bias.all() !=0 ):\n",
    "                    self.layer[-1-i].bias = self.layer[-1-i].bias - self.rp*self.layer[-1-i].bias/np.sqrt(np.sum(self.layer[-1-i].bias*self.layer[-1-i].bias))/self.layer[-1-i].bias.size  \n",
    "            else:\n",
    "                dout = self.layer[-1-i].FFeedBack(d[0],self.f[-1-i])\n",
    "                \n",
    "            d.insert(0,dout)\n",
    "            #print('dout\\n',d[0])\n",
    "            \n",
    "    def Loss(self,y,yhat):\n",
    "        loss = 0\n",
    "        hinge = 1 - y*yhat\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        hinge[hinge<0]=0\n",
    "        loss = np.sum(hinge)\n",
    "        loss *= self.rp\n",
    "        temp = 0\n",
    "        for l in self.layer:\n",
    "            if(l.tag != 'pool'):\n",
    "                temp += np.sum(l.weight*l.weight)\n",
    "                temp += np.sum(l.bias*l.bias)\n",
    "        return loss + np.sqrt(temp)\n",
    "\n",
    "    def Loss_dx(self,y,yhat):\n",
    "        hinge = 1 - y*yhat\n",
    "        #print('hinge\\n',hinge)\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        #print('hinge\\n',hinge)\n",
    "        summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "        #print('summed\\n',summed)\n",
    "        loss = np.zeros(y.shape)\n",
    "        for i in range(hinge.shape[0]):\n",
    "            if(hinge[i]>0):\n",
    "                loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "        #print('dloss\\n',loss)\n",
    "        loss *= self.rp\n",
    "        #print('dloss\\n',loss)\n",
    "        return loss   \n",
    "    \n",
    "    def FPredict(self, X_test):\n",
    "        images = X_test.reshape(X_test.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        f = images\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            images = F\n",
    "        yhat = self.probability(Z)\n",
    "       \n",
    "        # the rest is similar to the logistic regression\n",
    "        labels = np.arange(0,self.outdim+1)\n",
    "        num_test_samples = X_test.shape[0]\n",
    "        # find which index gives us the highest probability\n",
    "        ypred = np.zeros(num_test_samples, dtype=int)\n",
    "        for i in range(num_test_samples):\n",
    "            ypred[i] = labels[np.argmax(yhat[i,:])]\n",
    "        return ypred\n",
    "\n",
    "    def FTrain(self,epochs,batchsize,X,y,Xtest,ytest):\n",
    "        batches = int(np.ceil(X.shape[0]/batchsize))\n",
    "        for i in range(epochs):\n",
    "            for j in range(batches):\n",
    "                start = j*batchsize\n",
    "                end = start + batchsize\n",
    "                if(end > X.shape[0]):\n",
    "                    end = X.shape[0]\n",
    "                X_ = X[start:end]\n",
    "                y_ = y[start:end]\n",
    "                self.FFeedForward(X_)\n",
    "                self.FBackPropagation(y_)\n",
    "            if((i+1)%(epochs/10) == 0):\n",
    "                ypred = self.FPredict(Xtest)\n",
    "                print(i+1,accuracy(ypred.ravel(),ytest.ravel()),'\\n  Loss: ',self.Loss(y_,self.yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(feature_vector):\n",
    "    dim = int(np.sqrt(len(feature_vector)))\n",
    "    plt.gray()\n",
    "    plt.matshow(feature_vector.reshape(dim,dim))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_test(index1,index2,clearn_,Xp,Xt,y):\n",
    "    for index in range(index1,index2):\n",
    "        print('Image:',index)\n",
    "        plot_digit(Xp[index])\n",
    "        ypred = clearn_.FPredict(Xt[index].reshape(1,-1))\n",
    "        print('Label:', int(y[index]))\n",
    "        print('Prediction:',int(ypred))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.18666666666666668 \n",
      "  Loss:  132.66371543300727\n",
      "20 0.8666666666666667 \n",
      "  Loss:  127.44370592107963\n",
      "30 0.9422222222222222 \n",
      "  Loss:  127.29547340491636\n",
      "40 0.9644444444444444 \n",
      "  Loss:  127.42081091882275\n",
      "50 0.9622222222222222 \n",
      "  Loss:  127.69854486167054\n",
      "60 0.9666666666666667 \n",
      "  Loss:  127.90448736958191\n",
      "70 0.9644444444444444 \n",
      "  Loss:  128.01830413954275\n",
      "80 0.9666666666666667 \n",
      "  Loss:  128.09481132688856\n",
      "90 0.9666666666666667 \n",
      "  Loss:  128.1532488736793\n",
      "100 0.9711111111111111 \n",
      "  Loss:  128.24428482155108\n"
     ]
    }
   ],
   "source": [
    "dX_train, dy_train = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "dX_test, dy_test = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "dX_train_norm, dX_test_norm = normalize_features(dX_train, dX_test)\n",
    "dy_train_ohe, dy_test_ohe = one_hot_encoder(dy_train, dy_test)\n",
    "\n",
    "filt1_info = CInfo([8,-1,3,3])\n",
    "filt1 = CLayer('convolution',filt1_info)\n",
    "\n",
    "pool1_info = CInfo([-1,2,2],2,2)\n",
    "pool1 = CLayer('pool',pool1_info)\n",
    "\n",
    "#filt2_info = CInfo([8,-1,3,3])\n",
    "#filt2 = CLayer('convolution',filt2_info)\n",
    "\n",
    "#pool2_info = CInfo([-1,2,2],2,2)\n",
    "#pool2 = CLayer('pool',pool2_info)\n",
    "\n",
    "\n",
    "conn_info = CInfo([-1,100])\n",
    "conn = CLayer('connection',conn_info)\n",
    "\n",
    "im_channels = 1\n",
    "im_dim = int(np.sqrt(dX_train.shape[1]))\n",
    "out_class = 10\n",
    "dim = [im_channels,im_dim,im_dim]\n",
    "layers=[filt1,pool1,conn]\n",
    "lr = 0.05\n",
    "rp = 0.1\n",
    "\n",
    "digitscnn = CNN(dim,out_class,layers,lr,rp)\n",
    "\n",
    "epochs = 100\n",
    "batches = 10\n",
    "batchsize = int (np.ceil(dX_train_norm.shape[0]/batches))\n",
    "digitscnn.FTrain(epochs,\\\n",
    "           batchsize,\\\n",
    "           dX_train_norm,\\\n",
    "           dy_train_ohe,\\\n",
    "           dX_test_norm,\\\n",
    "           dy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.568 \n",
      "  Loss:  197.9968244831911\n",
      "4 0.756 \n",
      "  Loss:  190.86114242986582\n",
      "6 0.782 \n",
      "  Loss:  191.0205159539317\n",
      "8 0.806 \n",
      "  Loss:  190.62951097201767\n",
      "10 0.834 \n",
      "  Loss:  190.9820489420178\n"
     ]
    }
   ],
   "source": [
    "mX_train, my_train = read_dataset('MNIST_X_train.csv', 'MNIST_y_train.csv')\n",
    "mX_test, my_test = read_dataset('MNIST_X_test.csv', 'MNIST_y_test.csv')\n",
    "mX_train_norm, mX_test_norm = normalize_features(mX_train, mX_test)\n",
    "my_train_ohe, my_test_ohe = one_hot_encoder(my_train, my_test)\n",
    "\n",
    "filt_info = CInfo([8,-1,8,8])\n",
    "filt = CLayer('convolution',filt_info)\n",
    "\n",
    "pool_info = CInfo([-1,2,2],2,2)\n",
    "pool = CLayer('pool',pool_info)\n",
    "\n",
    "conn_info = CInfo([-1,100])\n",
    "conn = CLayer('connection',conn_info)\n",
    "\n",
    "im_channels = 1\n",
    "im_dim = int(np.sqrt(mX_train.shape[1]))\n",
    "out_class = 10\n",
    "dim = [im_channels,im_dim,im_dim]\n",
    "layers=[filt,pool,conn]\n",
    "lr = 0.1\n",
    "rp = 0.1\n",
    "\n",
    "mnistcnn = CNN(dim,out_class,layers,lr,rp)\n",
    "\n",
    "epochs = 20\n",
    "batches = 10\n",
    "batchsize = int (np.ceil(mX_train_norm.shape[0]/batches))\n",
    "mnistcnn.FTrain(epochs,\\\n",
    "           batchsize,\\\n",
    "           mX_train_norm,\\\n",
    "           my_train_ohe,\\\n",
    "           mX_test_norm,\\\n",
    "           my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.0 \n",
      "  Loss:  237.80378853507216\n",
      "4 0.02092050209205021 \n",
      "  Loss:  234.48976571022726\n",
      "6 0.0041841004184100415 \n",
      "  Loss:  234.42235484171\n",
      "8 0.0041841004184100415 \n",
      "  Loss:  233.93079969529285\n",
      "10 0.008368200836820083 \n",
      "  Loss:  234.0317132294477\n",
      "12 0.0041841004184100415 \n",
      "  Loss:  234.04735409615262\n",
      "14 0.0041841004184100415 \n",
      "  Loss:  234.0403404380356\n",
      "16 0.0041841004184100415 \n",
      "  Loss:  234.07886399935214\n",
      "18 0.0041841004184100415 \n",
      "  Loss:  234.28774972284737\n",
      "20 0.0041841004184100415 \n",
      "  Loss:  234.81548848858245\n"
     ]
    }
   ],
   "source": [
    "cX_train, cy_train = read_dataset('coil_X_train.csv', 'coil_y_train.csv')\n",
    "cX_test, cy_test = read_dataset('coil_X_test.csv', 'coil_y_test.csv')\n",
    "cX_train_norm, cX_test_norm = normalize_features(cX_train, cX_test)\n",
    "cy_train_ohe, cy_test_ohe = one_hot_encoder(cy_train, cy_test)\n",
    "\n",
    "\n",
    "filt_info = CInfo([8,-1,8,8])\n",
    "filt = CLayer('convolution',filt_info)\n",
    "\n",
    "pool_info = CInfo([-1,2,2],2,2)\n",
    "pool = CLayer('pool',pool_info)\n",
    "\n",
    "conn_info = CInfo([-1,100])\n",
    "conn = CLayer('connection',conn_info)\n",
    "\n",
    "im_channels = 1\n",
    "im_dim = int(np.sqrt(cX_train.shape[1]))\n",
    "out_class = 20\n",
    "dim = [im_channels,im_dim,im_dim]\n",
    "layers=[filt,pool,conn]\n",
    "lr = 0.1\n",
    "rp = 0.1\n",
    "\n",
    "coilcnn = CNN(dim,out_class,layers,lr,rp)\n",
    "\n",
    "epochs = 20\n",
    "batches = 10\n",
    "batchsize = int (np.ceil(cX_train_norm.shape[0]/batches))\n",
    "coilcnn.FTrain(epochs,\\\n",
    "           batchsize,\\\n",
    "           cX_train_norm,\\\n",
    "           cy_train_ohe,\\\n",
    "           cX_test_norm,\\\n",
    "           cy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-086304f97111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_digit(feature_vector):\n",
    "    dim = int(np.sqrt(len(feature_vector)))\n",
    "    plt.gray()\n",
    "    plt.matshow(feature_vector.reshape(dim,dim))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_test(index1,index2,clearn_,Xp,Xt,y):\n",
    "    for index in range(index1,index2):\n",
    "        print('Image:',index)\n",
    "        plot_digit(Xp[index])\n",
    "        ypred = clearn_.FPredict(Xt[index].reshape(1,-1))\n",
    "        print('Label:', int(y[index]))\n",
    "        print('Prediction:',int(ypred))\n",
    "        print('')\n",
    "\n",
    "for weight in cnn.layer[0].weight:\n",
    "    plt.gray()\n",
    "    print(weight.reshape(3,3))\n",
    "    plt.matshow(weight.reshape(3,3))\n",
    "    plt.show()\n",
    "plot_test(0,10,cnn,X_test,X_test_norm,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
