{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Here I've coded an artificial neural network with an arbitrary number of layers. The ANN is encoded in a class, and is fed a dictionary of your choices for activation functions and loss functions, as well as a list of the neurons in each layer, for example a two layer network with 100 and 50, respectively, is fed as [100,50].\n",
    "\n",
    "Then, the easiest way to search for effective parameters sets is to use RunOne or RunTwo. RunOne will train a one layer NN across the list of options you feed it, then test its accuracy. For example, [10,20,30] will train with 10 neurons, 20 neurons, 30 neurons, and spit out the accuracy for each. Similarly, RunTwo trains in a list of two lists, the first for the number of neurons in the first layer and the second for the second layer. It will train across all combinations and sit out a matrix of accuracies.\n",
    "\n",
    "Then, once you've identified a good parameter set, use the solitary Train function grouped with RunOne and RunTwo in order to train one a specific parameter set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def read_dataset(feature_file, label_file):\n",
    "    ''' Read data set in *.csv to data frame in Pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (features)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def normalize_features(X_train, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler #import libaray\n",
    "    scaler = StandardScaler() # call an object function\n",
    "    scaler.fit(X_train) # calculate mean, std in X_train\n",
    "    X_train_norm = scaler.transform(X_train) # apply normalization on X_train\n",
    "    X_test_norm = scaler.transform(X_test) # we use the same normalization on X_test\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "\n",
    "def one_hot_encoder(y_train, y_test):\n",
    "    ''' convert label to a vector under one-hot-code fashion '''\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    y_train_ohe = lb.transform(y_train)\n",
    "    y_test_ohe = lb.transform(y_test)\n",
    "    return y_train_ohe, y_test_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, X, y, DACT, DLOSS, filt=[(8,1,3,3)], stride=[1], hidden_layer=[100], lr=0.01):\n",
    "        self.X = X # features\n",
    "        self.y = y # labels (targets) in one-hot-encoder\n",
    "        self.imag_dim = np.sqrt(X.shape[1])\n",
    "        \n",
    "        self.activation = DACT['F']\n",
    "        self.derivative = DACT['D']\n",
    "        \n",
    "        self.lossfunction = DLOSS['F']\n",
    "        self.lossderivative = DLOSS['D']\n",
    "        \n",
    "        self.filter = filt\n",
    "        self.regularization_parameter = DLOSS['RP']\n",
    "        self.hidden_layer = hidden_layer # number of neuron in the hidden layer\n",
    "        \n",
    "        # In this example, we only consider 1 hidden layer\n",
    "        self.lr = lr # learning rate\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.in_nn = X.shape[1] # number of neurons in the inpute layer              \n",
    "        self.out_nn = y.shape[1]\n",
    "        \n",
    "        self.f[]\n",
    "        for i in range(0,len(self.filter):\n",
    "            self.f.append(InitializeFilter(self.filter[i]))\n",
    "                    \n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        self.W.append(np.random.randn(self.in_nn,self.hidden_layer[0])/np.sqrt(self.in_nn))\n",
    "        self.b.append(np.zeros((1,self.hidden_layer[0])))\n",
    "        for i in range(0,len(self.hidden_layer)-1):\n",
    "            self.W.append(np.random.randn(self.hidden_layer[i],self.hidden_layer[i+1])/np.sqrt(self.hidden_layer[i]))\n",
    "            self.b.append(np.zeros((1,self.hidden_layer[i+1])))\n",
    "\n",
    "        self.W.append(np.random.randn(self.hidden_layer[-1],self.out_nn)/np.sqrt(self.hidden_layer[-1]))\n",
    "        self.b.append(np.zeros((1,self.out_nn)))\n",
    "        self.C = [self.W,self.b]\n",
    "        \n",
    "    def feed_forward(self):\n",
    "        # hidden layer\n",
    "        self.z = []\n",
    "        self.f = []\n",
    "        ## z_1 = xW_1 + b_1\n",
    "        self.\n",
    "        self.z.append(np.dot(self.X, self.W[0]) + self.b[0])\n",
    "        ## activation function :  f_1 = \\tanh(z_1)\n",
    "        self.f.append(self.activation(self.z[0]))\n",
    "        for i in range(0,len(self.hidden_layer)-1):\n",
    "            self.z.append(np.dot(self.f[i], self.W[i+1]) + self.b[i+1])\n",
    "            self.f.append(self.activation(self.z[-1]))\n",
    "        # output layer\n",
    "        ## z_2 = f_1W_2 + b_2\n",
    "        self.z.append(np.dot(self.f[-1], self.W[-1]) + self.b[-1])\n",
    "        #\\hat{y} = softmax}(z_2)$\n",
    "        self.y_hat = softmax(self.z[-1])\n",
    "        \n",
    "        \n",
    "    def back_propagation(self):\n",
    "        d = []\n",
    "        d.insert(0,self.lossderivative(self.y,self.y_hat,self.regularization_parameter,self.C))\n",
    "        dW = []\n",
    "        db = []\n",
    "        for i in range(len(self.hidden_layer)):\n",
    "            dW.insert(0,self.f[-1-i].T.dot(d[0]))\n",
    "            db.insert(0,np.sum(d[0],axis=0,keepdims=True))\n",
    "            d.insert(0,self.derivative(self.f[-1-i])*(d[0].dot(self.W[-1-i].T)))\n",
    "        dW.insert(0,self.X.T.dot(d[0]))\n",
    "        db.insert(0,np.sum(d[0],axis=0,keepdims=True))\n",
    "        \n",
    "        \n",
    "        # Update the gradident descent\n",
    "        if(self.regularization_parameter==None):\n",
    "            for i in range(len(self.W)):            \n",
    "                self.W[i] = self.W[i] - self.lr * dW[i]\n",
    "                self.b[i] = self.b[i] - self.lr * db[i]\n",
    "        else:\n",
    "            for i in range(len(self.W)):\n",
    "                self.W[i] = self.W[i] - self.lr * dW[i]\n",
    "                if(self.W[i].all()!=0):\n",
    "                    self.W[i] = self.W[i] - self.lr * self.W[i]/np.sqrt(np.sum(self.W[i]*self.W[i]))\n",
    "                self.b[i] = self.b[i] - self.lr * db[i]\n",
    "                if(self.b[i].all()!=0):\n",
    "                    self.b[i] = self.b[i] - self.lr * self.b[i]/np.sqrt(np.sum(self.b[i]*self.b[i]))\n",
    "\n",
    "    def callloss(self):\n",
    "        #  $L = -\\sum_n\\sum_{i\\in C} y_{n, i}\\log(\\hat{y}_{n, i})$\n",
    "        # calculate y_hat\n",
    "        self.feed_forward()\n",
    "        self.loss = self.lossfunction(self.y,self.y_hat,self.regularization_parameter,self.C)\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Use feed forward to calculat y_hat_test\n",
    "        # hidden layer\n",
    "        ## z_1 = xW_1 + b_1\n",
    "        z = np.dot(X_test, self.W[0]) + self.b[0]\n",
    "        for i in range(1,len(self.hidden_layer)+1):\n",
    "            f = self.activation(z)\n",
    "            z = np.dot(f,self.W[i]) + self.b[i]\n",
    "        y_hat_test = softmax(z)\n",
    "\n",
    "        # the rest is similar to the logistic regression\n",
    "        labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        num_test_samples = X_test.shape[0]\n",
    "        # find which index gives us the highest probability\n",
    "        ypred = np.zeros(num_test_samples, dtype=int)\n",
    "        for i in range(num_test_samples):\n",
    "            ypred[i] = labels[np.argmax(y_hat_test[i,:])]\n",
    "        return ypred\n",
    "    \n",
    "    def train(self,epochs):\n",
    "        for i in range(epochs):\n",
    "            self.feed_forward()\n",
    "            self.back_propagation()\n",
    "            self.callloss()\n",
    "        \n",
    "def softmax(z):\n",
    "    exp_value = np.exp(z-np.amax(z, axis=1, keepdims=True)) # for stablility\n",
    "    # keepdims = True means that the output's dimension is the same as of z\n",
    "    softmax_scores = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
    "    return softmax_scores\n",
    "\n",
    "def accuracy(ypred, yexact):\n",
    "    p = np.array(ypred == yexact, dtype = int)\n",
    "    return np.sum(p)/float(len(yexact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n",
      "(1347, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "X_train_digits, y_train_digits = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test_digits, y_test_digits = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "X_train_norm_digits, X_test_norm_digits = normalize_features(X_train_digits, X_test_digits)\n",
    "y_train_ohe_digits, y_test_ohe_digits = one_hot_encoder(y_train_digits, y_test_digits)\n",
    "\n",
    "print(X_train_digits.shape)\n",
    "X_train_digits = np.reshape(X_train_digits,(-1,8,8))\n",
    "print(X_train_digits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def InitializeFilter(dimensions):\n",
    "    return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(dimensions))),size=dimensions)\n",
    "\n",
    "\n",
    "def Convolution(images, filt, bias, activat, stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - f_i)/stride_i) + 1)\n",
    "    out_j = int(np.ceil((imag_j - f_j)/stride_j) + 1)\n",
    "    z = np.zeros((num_imag, num_filt, out_i, out_j))\n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            f_y_end = f_j + 1\n",
    "            while(out_y < out_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_i + 1\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_x\n",
    "                    z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + bias[curr_f]\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,activat(z)\n",
    "\n",
    "def FMaxPool(images,pool_i=2,pool_j=2,stride_i=2,stride_j=2):\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - pool_i)/stride_i)) + 1\n",
    "    out_j = int(np.ceil((imag_j - pool_j)/stride_j)) + 1\n",
    "    z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    index = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    \n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_chan in range(num_ch):\n",
    "            curr_y = out_y = 0\n",
    "            while(out_y < out_j):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + pool_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    current_y_end = imag_j\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + pool_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,index\n",
    "\n",
    "def FConnection(images,weights,bias,activation):\n",
    "    z = images.dot(weights) + bias\n",
    "    return z, activation(z)\n",
    "\n",
    "def FbackConvolution(dprev,conv_in,filt,derivative,stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dbias = np.zeros((num_filt,1))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        dout_conv = np.zeros((num_ch,imag_i,imag_j))\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = out_y = 0\n",
    "            f_y_end = f_i\n",
    "            while(curr_y + f_j < imag_j + 1):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_j\n",
    "                while(curr_x + f_i < imag_i + 1): \n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_i\n",
    "                    dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\n",
    "                    dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "            dbias[curr_f] = np.sum(dprev[curr_f])\n",
    "        dout += dout_conv*derivative(conv)\n",
    "\n",
    "    return dout,dfilt,dbias\n",
    "\n",
    "def FbackMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2):\n",
    "    (num_ch_p, dp_i, dp_j) = dpool.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_p != num_ch):\n",
    "        print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        for curr_ch in range(num_ch):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            while(out_y < dp_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + p_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                while(out_x < dp_i):\n",
    "                    curr_x_end = curr_x + p_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                    dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "    return dout\n",
    "\n",
    "def FbackConnection(dprev,data_in,weight,activation,derivative):\n",
    "    dW = activation(data_in).T.dot(dprev)\n",
    "    db = np.sum(dprev,axis=0,keepdims=True)\n",
    "    dout = dprev.dot(weight.T)*derivative(data_in)\n",
    "    return dout, dW, db\n",
    "    \n",
    "#def Convolution(images, filt, bias, activation, stride_i=1,stride_j=1):\n",
    "\n",
    "\n",
    "def FLinear(X):\n",
    "    return X\n",
    "def FRELU(X):\n",
    "    a = np.copy(X)\n",
    "    a[X<0]=0\n",
    "    return a\n",
    "def FRELU_dx(X):\n",
    "    dx = np.zeros(X.shape)\n",
    "    dx[X>0] = 1\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW IS TESTING! DIVE IN; THE WATER'S FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFilter:\n",
    "    def __init__(self,dimensions,stride_i=1,stride_j=1,activation=RELU):\n",
    "        self.dimensions = dimensions\n",
    "        self.num_filt = dimensions[0]\n",
    "        self.num_ch = dimensions[1]\n",
    "        self.f_i = dimensions[2]\n",
    "        self.f_j = dimensions[3]\n",
    "        self.filt = self.FInitializeFilter()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.stride_i = stride_i\n",
    "        self.stride_j = stride_j\n",
    "        self.activation = activation        \n",
    "    def FInitializeFilter(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.dimensions))),size=self.dimensions)\n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.num_filt))),size=self.num_filt)\n",
    "    \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.f_i)/self.stride_i) + 1)\n",
    "        out_j = int(np.ceil((imag_j - self.f_j)/self.stride_j) + 1)\n",
    "        z = np.zeros((num_imag, self.num_filt, out_i, out_j))\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                f_y_end = self.f_j\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y\n",
    "                    f_x_end = self.f_i\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x\n",
    "                        z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + self.bias[curr_f]\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,imag_in):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "        dfilt = np.zeros(filt.shape)\n",
    "        dbias = np.zeros((self.num_filt,1))\n",
    "\n",
    "        for conv in imag_in:\n",
    "            dout_conv = np.zeros((self.num_ch,imag_i,imag_j))\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = out_y = 0\n",
    "                f_y_end = f_i\n",
    "                while(curr_y + self.f_j < imag_j + 1):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y\n",
    "                    f_x_end = self.f_j\n",
    "                    while(curr_x + self.f_i < imag_i + 1): \n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_i\n",
    "                        dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\n",
    "                        dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "                dbias[curr_f] = np.sum(dprev[curr_f])\n",
    "            dout += dout_conv*self.activation.d(conv)\n",
    "\n",
    "        return dout,dfilt,dbias\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Filter Information:\")\n",
    "        print(\"  num_filt:\",self.num_filt)\n",
    "        print(\"  num_ch:\",self.num_ch)\n",
    "        print(\"  f_i:\",self.f_i)\n",
    "        print(\"  f_j:\",self.f_j)\n",
    "        print(\"  stride_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "        print(\"  act.f:\",self.activation.f)\n",
    "        print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  filt:\\n\",self.filt)\n",
    "        print(\"  bias:\\n\",self.bias)\n",
    "\n",
    "class CPool:\n",
    "    def __init__(self,dimensions,stride_i=1,stride_j=1):\n",
    "        self.dimensions = dimensions\n",
    "        self.pool_i = dimensions[0]\n",
    "        self.pool_j = dimensions[1]\n",
    "        self.stride_i = stride_i\n",
    "        self.stride_j = stride_j  \n",
    "        \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.pool_i)/self.stride_i)) + 1\n",
    "        out_j = int(np.ceil((imag_j - self.pool_j)/self.stride_j)) + 1\n",
    "        z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "        index = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_chan in range(num_ch):\n",
    "                curr_y = out_y = 0\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        current_y_end = imag_j\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan, curr_x:curr_x_end, curr_y:curr_y_end])\n",
    "                        index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan, curr_x:curr_x_end, curr_y:curr_y_end])\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,index\n",
    "\n",
    "    def FFeedBack(self, dprev, imag_in):\n",
    "        (num_ch_p, dp_i, dp_j) = dprev.shape\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(num_ch_p != num_ch):\n",
    "            print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "\n",
    "        for conv in conv_in:\n",
    "            for curr_ch in range(num_ch):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                while(out_y < dp_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                    while(out_x < dp_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                        dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "        return dout\n",
    "\n",
    "\n",
    "    \n",
    "    def FPrint(self):\n",
    "        print(\"Pool Information:\")\n",
    "        print(\"  pool_i:\",self.pool_i)\n",
    "        print(\"  pool_j:\",self.pool_j)\n",
    "        print(\"  stide_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "\n",
    "class CConnection:\n",
    "    def __init__(self,dimensions,activation):\n",
    "        self.dimensions = dimensions\n",
    "        self.neurons_in = dimensions[0]\n",
    "        self.neurons_out = dimensions[1]\n",
    "        self.weights = self.FInitializeWeights()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.activation = activation\n",
    "   \n",
    "    def FInitializeWeights(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.dimensions))),size=self.dimensions)\n",
    "       \n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.neurons_out))),size=self.neurons_out)\n",
    "\n",
    "    def FFeedForward(self,images):\n",
    "        z = images.dot(self.weights) + self.bias\n",
    "        return z, self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,data_in):\n",
    "        dW = self.activation.f(data_in).T.dot(dprev)\n",
    "        db = np.sum(dprev,axis=0,keepdims=True)\n",
    "        dout = dprev.dot(weight.T)*self.activation.d(data_in)\n",
    "        return dout, dW, db\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Connection Information:\")\n",
    "        print(\"  neurons_in:\",self.neurons_in)\n",
    "        print(\"  neurons_out:\",self.neurons_out)\n",
    "        print(\"  act.f:\",self.activation.f)\n",
    "        print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  weights:\\n\",self.weights)\n",
    "        print(\"  bais:\\n\",self.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Information:\n",
      "  num_filt: 1\n",
      "  num_ch: 1\n",
      "  f_x: 5\n",
      "  f_y: 5\n",
      "  s_x: 1\n",
      "  s_y: 1\n",
      "  act.f: <function FRELU at 0x1064629d8>\n",
      "  act.d: <function FRELU_dx at 0x114847620>\n",
      "  filt:\n",
      " [[[[-0.13454688  0.02816533 -0.11456706  0.27964034 -0.17523139]\n",
      "   [-0.02580058 -0.03945629  0.11198262 -0.02416673  0.21829003]\n",
      "   [-0.11701991 -0.2042812   0.13541521 -0.08904266 -0.1312717 ]\n",
      "   [ 0.35041405  0.04686846 -0.51521201 -0.03540453  0.25502236]\n",
      "   [ 0.06665609 -0.12658928  0.10565756 -0.06891326 -0.26130157]]]]\n",
      "Pool Information:\n",
      "  num_ch: 1\n",
      "  p_x: 2\n",
      "  p_y: 2\n",
      "  s_x: 1\n",
      "  s_y: 1\n",
      "Connection Information:\n",
      "  neurons_in: 2\n",
      "  neurons_out: 3\n",
      "  act.f: <function FRELU at 0x1064629d8>\n",
      "  act.d: <function FRELU_dx at 0x114847620>\n",
      "  weights:\n",
      " [[ 0.06913202  0.35233589 -0.18735471]\n",
      " [ 0.49062954  0.47251516 -0.75670941]]\n",
      "  bais:\n",
      " [-0.26986263  0.41826881 -0.28163548]\n"
     ]
    }
   ],
   "source": [
    "layers=[]\n",
    "X = np.zeros((1,5))\n",
    "y = np.zeros(1)\n",
    "out = 5\n",
    "size_x = size_y = 3\n",
    "stride_x = stride_y = 1\n",
    "activation = linear\n",
    "layer0 = [\"initial\",X,y,out,size_x,size_y]\n",
    "layer1 = [\"convolution\",out,size_x,size_y,stride_x,stride_y,activation]\n",
    "layer2 = [\"pool\",out,size_x,size_y,stride_x,stride_y]\n",
    "layer3 = [\"connection\",out,activation]\n",
    "layer4 = [\"final\",out,activation]\n",
    "layers.append(layer0)\n",
    "layers.append(layer1)\n",
    "layers.append(layer2)\n",
    "layers.append(layer3)\n",
    "layers.append(layer4)\n",
    "\n",
    "class CActivation:\n",
    "    def __init__(self,Function,Derivative):\n",
    "        self.f = Function\n",
    "        self.d = Derivative\n",
    "\n",
    "class CLayer:\n",
    "    def __init__(self,Tag,Info):\n",
    "        self.tag = Tag\n",
    "        self.info = Info\n",
    "\n",
    "\n",
    "RELU = CActivation(FRELU,FRELU_dx)\n",
    "testfilter = CFilter((1,1,5,5),1,1,RELU)\n",
    "testfilter.FPrint()\n",
    "testpool = CPool((1,2,2),1,1)\n",
    "testpool.FPrint()\n",
    "testconnection = CConnection((2,3),RELU)\n",
    "testconnection.FPrint()\n",
    "        \n",
    "act = CActivation(RELU,RELU_dx)\n",
    "info = {'out':4,\\\n",
    "       'size_x':3,\\\n",
    "       'size_y':3,\\\n",
    "       'stride_x':1,\\\n",
    "       'stride_y':1,\\\n",
    "       'activation':act.f,\\\n",
    "       'derivative':act.d}\n",
    "conv = CLayer(\"convolution\",info)\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, X, y, LayersInfo):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.layer = []\n",
    "        for i in range(1,LayersInfo):\n",
    "            if(Layer.tag == \"convolution\"):\n",
    "                print('yes!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dprev:\n",
      " [[0. 1. 2. 3. 4.]\n",
      " [1. 2. 3. 4. 5.]]\n",
      "weight:\n",
      " [[ 0.  1.  2.  3.  4.]\n",
      " [ 1.  2.  3.  4.  5.]\n",
      " [ 2.  3.  4.  5.  6.]\n",
      " [ 3.  4.  5.  6.  7.]\n",
      " [ 4.  5.  6.  7.  8.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [ 6.  7.  8.  9. 10.]]\n",
      "data:\n",
      " [[0. 1. 2. 3. 4. 5. 6.]\n",
      " [1. 2. 3. 4. 5. 6. 7.]]\n",
      "dout:\n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "dW:\n",
      " [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "db:\n",
      " [[0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "dprev = np.zeros((2,5))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        dprev[i,j] = i + j\n",
    "weight = np.zeros((7,5))\n",
    "for i in range(7):\n",
    "    for j in range(5):\n",
    "        weight[i,j] = i + j\n",
    "data_in = np.zeros((2,7))\n",
    "for i in range(2):\n",
    "    for j in range(7):\n",
    "        data_in[i,j] = i + j\n",
    "dout, dW, db = backConnection(dprev,data_in,weight,FRELU,FRELU_dx)\n",
    "print(\"dprev:\\n\",dprev)\n",
    "print(\"weight:\\n\",weight)\n",
    "print(\"data:\\n\",data_in)\n",
    "\n",
    "        \n",
    "testconnection = CConnection((7,5),RELU)\n",
    "testconnection.weight = weight\n",
    "dout__,dW__,db__ = testconnection.FFeedBack(dprev,data_in)\n",
    "\n",
    "print(\"dout:\\n\",dout__-dout)\n",
    "print(\"dW:\\n\",dW__-dW)\n",
    "print(\"db:\\n\",db__-db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpool:\n",
      " [[[ 0. -1. -2.]\n",
      "  [ 1.  0. -1.]\n",
      "  [ 2.  1.  0.]]\n",
      "\n",
      " [[ 1.  0. -1.]\n",
      "  [ 2.  1.  0.]\n",
      "  [ 3.  2.  1.]]]\n",
      "conv_in:\n",
      " [[[[ 0. -1. -2. -3. -4. -5.]\n",
      "   [ 1.  0. -1. -2. -3. -4.]\n",
      "   [10.  1.  0. -1. -2. -3.]\n",
      "   [ 3.  2.  1.  0. -1. -2.]\n",
      "   [ 4.  3.  2.  1.  0. -1.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  0. -1. -2. -3. -4.]\n",
      "   [ 2.  1.  0. -1. -2. -3.]\n",
      "   [ 3.  2.  1.  0. -1. -2.]\n",
      "   [ 4.  3.  2.  1.  0. -1.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]\n",
      "   [ 6.  5.  4.  3.  2.  1.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.]]]]\n",
      "dout:\n",
      " [[[ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0. -2.  0. -4.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0. -2.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 4.  0.  2.  0.  0.  0.]]\n",
      "\n",
      " [[ 2.  0.  0.  0. -2.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 4.  0.  2.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]\n",
      "  [ 6.  0.  4.  0.  2.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "dpool = np.zeros((2,3,3))\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            dpool[i,j,k] = i + j - k\n",
    "conv_in = np.zeros((2,2,6,6))\n",
    "for i in range(2):\n",
    "    for j in range(1):\n",
    "        for k in range(6):\n",
    "            for l in range(6):\n",
    "                conv_in[i,j,k,l] = i + j + k - l\n",
    "conv_in[0,0,2,0] = 10\n",
    "\n",
    "dout = backMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2)\n",
    "print(\"dpool:\\n\",dpool)\n",
    "print(\"conv_in:\\n\",conv_in)\n",
    "print(\"dout:\\n\",dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dprev:\n",
      " [[[1. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[2. 0. 0. 2.]\n",
      "  [2. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [2. 0. 0. 0.]]]\n",
      "conv:\n",
      " [[[[1.  0.  0.  0.  1.3]\n",
      "   [1.2 0.  0.  0.  0. ]\n",
      "   [0.  0.  0.  0.  0. ]\n",
      "   [0.  0.  0.  0.  0. ]\n",
      "   [1.7 0.  0.  0.  0. ]]\n",
      "\n",
      "  [[1.  0.  0.  0.  1. ]\n",
      "   [1.  0.  0.  0.  0. ]\n",
      "   [0.  0.  0.  0.  0. ]\n",
      "   [0.  0.  0.  0.  0. ]\n",
      "   [1.  0.  0.  0.  0. ]]]]\n",
      "f:\n",
      " [[[[1.  1. ]\n",
      "   [1.  1. ]]\n",
      "\n",
      "  [[1.  0. ]\n",
      "   [0.  1. ]]]\n",
      "\n",
      "\n",
      " [[[0.7 0.5]\n",
      "   [0.3 0.6]]\n",
      "\n",
      "  [[0.  1. ]\n",
      "   [1.  0. ]]]]\n",
      "d:\n",
      " [[[2.4 0.  0.  0.  2. ]\n",
      "  [4.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [1.6 0.  0.  0.  0. ]]\n",
      "\n",
      " [[1.  0.  0.  0.  2. ]\n",
      "  [3.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [2.  0.  0.  0.  0. ]]]\n",
      "df:\n",
      " [[[[2.2 1.3]\n",
      "   [2.9 0. ]]\n",
      "\n",
      "  [[2.  1. ]\n",
      "   [2.  0. ]]]\n",
      "\n",
      "\n",
      " [[[4.4 2.6]\n",
      "   [5.8 0. ]]\n",
      "\n",
      "  [[4.  2. ]\n",
      "   [4.  0. ]]]]\n",
      "db:\n",
      " [[4.]\n",
      " [8.]]\n"
     ]
    }
   ],
   "source": [
    "dprev = np.zeros((2,4,4))\n",
    "dprev[0,0,0] = 1\n",
    "dprev[0,1,0] = 1\n",
    "dprev[0,0,3] = 1\n",
    "dprev[0,3,0] = 1\n",
    "dprev[1,0,0] = 2\n",
    "dprev[1,1,0] = 2\n",
    "dprev[1,0,3] = 2\n",
    "dprev[1,3,0] = 2\n",
    "conv_in = np.zeros((1,2,5,5))\n",
    "conv_in[0,0,0,0] = 1\n",
    "conv_in[0,0,1,0] = 1.2\n",
    "conv_in[0,0,0,4] = 1.3\n",
    "conv_in[0,0,4,0] = 1.7\n",
    "conv_in[0,1,0,0] = 1\n",
    "conv_in[0,1,1,0] = 1\n",
    "conv_in[0,1,0,4] = 1\n",
    "conv_in[0,1,4,0] = 1\n",
    "filt = np.zeros((2,2,2,2))\n",
    "filt[0,0,0,0] = 1\n",
    "filt[0,0,1,1] = 1\n",
    "filt[0,0,0,1] = 1\n",
    "filt[0,0,1,0] = 1\n",
    "filt[1,0,0,0] = 0.7\n",
    "filt[1,0,1,1] = 0.6\n",
    "filt[1,0,0,1] = 0.5\n",
    "filt[1,0,1,0] = 0.3\n",
    "filt[0,1,0,0] = 1\n",
    "filt[0,1,1,1] = 1\n",
    "filt[1,1,0,1] = 1\n",
    "filt[1,1,1,0] = 1\n",
    "dout, dfilt, dbias = backConvolution(dprev,conv_in,filt,RELU_dx,stride_i=1,stride_j=1)\n",
    "print(\"dprev:\\n\",dprev)\n",
    "print(\"conv:\\n\",conv_in)\n",
    "print(\"f:\\n\",filt)\n",
    "print(\"d:\\n\",dout)\n",
    "print(\"df:\\n\",dfilt)\n",
    "print(\"db:\\n\",dbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Information:\n",
      "  num_filt: 2\n",
      "  num_ch: 2\n",
      "  f_i: 2\n",
      "  f_j: 2\n",
      "  stride_i: 2\n",
      "  stride_j: 2\n",
      "  act.f: <function FRELU at 0x1064629d8>\n",
      "  act.d: <function FRELU_dx at 0x114847620>\n",
      "  filt:\n",
      " [[[[1. 0.]\n",
      "   [0. 1.]]\n",
      "\n",
      "  [[1. 0.]\n",
      "   [0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [1. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [1. 0.]]]]\n",
      "  bias:\n",
      " [1.3 1.1]\n",
      "Pool Information:\n",
      "  pool_i: 2\n",
      "  pool_j: 2\n",
      "  stide_i: 2\n",
      "  stride_j: 2\n",
      "filt:\n",
      " [[[[1. 0.]\n",
      "   [0. 1.]]\n",
      "\n",
      "  [[1. 0.]\n",
      "   [0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [1. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [1. 0.]]]]\n",
      "image:\n",
      " [[[[ 0. -1. -2. -3. -4.  0.]\n",
      "   [ 1.  0. -1. -2. -3.  0.]\n",
      "   [ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]]\n",
      "\n",
      "  [[ 1.  0. -1. -2. -3.  0.]\n",
      "   [ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  0. -1. -2. -3.  0.]\n",
      "   [ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]]\n",
      "\n",
      "  [[ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]\n",
      "   [ 6.  5.  4.  3.  2.  0.]]]]\n",
      "zc:\n",
      " [[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]]\n",
      "conv:\n",
      " [[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]]\n",
      "pool:\n",
      " [[[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]]\n",
      "pool_index:\n",
      " [[[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]]\n",
      "flat:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "testfilter = CFilter((2,2,2,2),2,2,RELU)\n",
    "testfilter.filt = np.zeros((2,2,2,2))\n",
    "testfilter.filt[0,0,0,0] = 1\n",
    "testfilter.filt[0,0,0,1] = 0\n",
    "testfilter.filt[0,0,1,0] = 0\n",
    "testfilter.filt[0,0,1,1] = 1\n",
    "testfilter.filt[1,0,0,0] = 0\n",
    "testfilter.filt[1,0,0,1] = 0\n",
    "testfilter.filt[1,0,1,0] = 1\n",
    "testfilter.filt[1,0,1,1] = 0\n",
    "testfilter.filt[0,1,0,0] = 1\n",
    "testfilter.filt[0,1,0,1] = 0\n",
    "testfilter.filt[0,1,1,0] = 0\n",
    "testfilter.filt[0,1,1,1] = 1\n",
    "testfilter.filt[1,1,0,0] = 0\n",
    "testfilter.filt[1,1,0,1] = 0\n",
    "testfilter.filt[1,1,1,0] = 1\n",
    "testfilter.filt[1,1,1,1] = 0\n",
    "\n",
    "testfilter.bias = np.zeros(2)\n",
    "testfilter.bias[0] = 1.3\n",
    "testfilter.bias[1] = 1.1\n",
    "                \n",
    "testfilter.FPrint()\n",
    "\n",
    "image__ = np.zeros((2,2,5,6))\n",
    "for m in range(2):\n",
    "    for k in range(2):\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                image__[m,k,i,j] = k+i - j+m\n",
    "\n",
    "zc__,conv__ = testfilter.FFeedForward(image__)\n",
    "\n",
    "testpool = CPool((2,2),2,2)\n",
    "testpool.FPrint()\n",
    "pool__,index__ = testpool.FFeedForward(conv__)\n",
    "\n",
    "filt = InitializeFilter((2,2,2,2))\n",
    "filt[0,0,0,0] = 1\n",
    "filt[0,0,0,1] = 0\n",
    "filt[0,0,1,0] = 0\n",
    "filt[0,0,1,1] = 1\n",
    "filt[1,0,0,0] = 0\n",
    "filt[1,0,0,1] = 0\n",
    "filt[1,0,1,0] = 1\n",
    "filt[1,0,1,1] = 0\n",
    "filt[0,1,0,0] = 1\n",
    "filt[0,1,0,1] = 0\n",
    "filt[0,1,1,0] = 0\n",
    "filt[0,1,1,1] = 1\n",
    "filt[1,1,0,0] = 0\n",
    "filt[1,1,0,1] = 0\n",
    "filt[1,1,1,0] = 1\n",
    "filt[1,1,1,1] = 0\n",
    "print(\"filt:\\n\",filt)\n",
    "image = np.zeros((2,2,5,6))\n",
    "bias = np.zeros(2)\n",
    "bias[0] = 1.3\n",
    "bias[1] = 1.1\n",
    "\n",
    "print(\"image:\\n\",image__)\n",
    "zc,conv = Convolution(image__,testfilter.filt,testfilter.bias,testfilter.activation.f,testfilter.stride_i,testfilter.stride_j)\n",
    "print(\"zc:\\n\",zc__-zc)\n",
    "print(\"conv:\\n\",conv__-conv)\n",
    "pool,index = MaxPool(conv)\n",
    "print(\"pool:\\n\",pool__-pool)\n",
    "print(\"pool_index:\\n\",index__-index)\n",
    "print(\"flat:\\n\",pool__.reshape(pool__.shape[0],-1)-pool.reshape(pool.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filt:\n",
      " [[[[1. 0.]\n",
      "   [0. 1.]]\n",
      "\n",
      "  [[1. 0.]\n",
      "   [0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [1. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [1. 0.]]]]\n",
      "bias:\n",
      " [1.3 1.1]\n",
      "image:\n",
      " [[[[ 0. -1. -2. -3. -4.  0.]\n",
      "   [ 1.  0. -1. -2. -3.  0.]\n",
      "   [ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]]\n",
      "\n",
      "  [[ 1.  0. -1. -2. -3.  0.]\n",
      "   [ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  0. -1. -2. -3.  0.]\n",
      "   [ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]]\n",
      "\n",
      "  [[ 2.  1.  0. -1. -2.  0.]\n",
      "   [ 3.  2.  1.  0. -1.  0.]\n",
      "   [ 4.  3.  2.  1.  0.  0.]\n",
      "   [ 5.  4.  3.  2.  1.  0.]\n",
      "   [ 6.  5.  4.  3.  2.  0.]]]]\n",
      "zc:\n",
      " [[[[ 3.3 -4.7 -5.7]\n",
      "   [11.3  3.3 -1.7]\n",
      "   [10.3  6.3  2.3]]\n",
      "\n",
      "  [[ 4.1  0.1 -3.9]\n",
      "   [ 8.1  4.1  0.1]\n",
      "   [ 1.1  1.1  1.1]]]\n",
      "\n",
      "\n",
      " [[[ 7.3 -0.7 -3.7]\n",
      "   [15.3  7.3  0.3]\n",
      "   [12.3  8.3  4.3]]\n",
      "\n",
      "  [[ 6.1  2.1 -1.9]\n",
      "   [10.1  6.1  2.1]\n",
      "   [ 1.1  1.1  1.1]]]]\n",
      "conv:\n",
      " [[[[ 3.3  0.   0. ]\n",
      "   [11.3  3.3  0. ]\n",
      "   [10.3  6.3  2.3]]\n",
      "\n",
      "  [[ 4.1  0.1  0. ]\n",
      "   [ 8.1  4.1  0.1]\n",
      "   [ 1.1  1.1  1.1]]]\n",
      "\n",
      "\n",
      " [[[ 7.3  0.   0. ]\n",
      "   [15.3  7.3  0.3]\n",
      "   [12.3  8.3  4.3]]\n",
      "\n",
      "  [[ 6.1  2.1  0. ]\n",
      "   [10.1  6.1  2.1]\n",
      "   [ 1.1  1.1  1.1]]]]\n",
      "pool:\n",
      " [[[[11.3  0. ]\n",
      "   [10.3  2.3]]\n",
      "\n",
      "  [[ 8.1  0.1]\n",
      "   [ 1.1  1.1]]]\n",
      "\n",
      "\n",
      " [[[15.3  0.3]\n",
      "   [12.3  4.3]]\n",
      "\n",
      "  [[10.1  2.1]\n",
      "   [ 1.1  1.1]]]]\n",
      "pool_index:\n",
      " [[[[2. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[2. 1.]\n",
      "   [0. 0.]]]\n",
      "\n",
      "\n",
      " [[[2. 1.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[2. 1.]\n",
      "   [0. 0.]]]]\n",
      "flat:\n",
      " [[11.3  0.  10.3  2.3  8.1  0.1  1.1  1.1]\n",
      " [15.3  0.3 12.3  4.3 10.1  2.1  1.1  1.1]]\n"
     ]
    }
   ],
   "source": [
    "filt = InitializeFilter((2,2,2,2))\n",
    "filt[0,0,0,0] = 1\n",
    "filt[0,0,0,1] = 0\n",
    "filt[0,0,1,0] = 0\n",
    "filt[0,0,1,1] = 1\n",
    "filt[1,0,0,0] = 0\n",
    "filt[1,0,0,1] = 0\n",
    "filt[1,0,1,0] = 1\n",
    "filt[1,0,1,1] = 0\n",
    "filt[0,1,0,0] = 1\n",
    "filt[0,1,0,1] = 0\n",
    "filt[0,1,1,0] = 0\n",
    "filt[0,1,1,1] = 1\n",
    "filt[1,1,0,0] = 0\n",
    "filt[1,1,0,1] = 0\n",
    "filt[1,1,1,0] = 1\n",
    "filt[1,1,1,1] = 0\n",
    "print(\"filt:\\n\",filt)\n",
    "image = np.zeros((2,2,5,6))\n",
    "bias = np.zeros(2)\n",
    "bias[0] = 1.3\n",
    "bias[1] = 1.1\n",
    "print(\"bias:\\n\",bias)\n",
    "for m in range(2):\n",
    "    for k in range(2):\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                image[m,k,i,j] = k+i - j+m\n",
    "print(\"image:\\n\",image)\n",
    "zc,conv = Convolution(image,filt,bias,FRELU,stride_i=2,stride_j=2)\n",
    "print(\"zc:\\n\",zc)\n",
    "print(\"conv:\\n\",conv)\n",
    "pool,index = MaxPool(conv)\n",
    "print(\"pool:\\n\",pool)\n",
    "print(\"pool_index:\\n\",index)\n",
    "print(\"flat:\\n\",pool.reshape(pool.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
