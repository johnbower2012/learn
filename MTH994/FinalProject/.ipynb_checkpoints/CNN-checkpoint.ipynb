{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Here I've coded an artificial neural network with an arbitrary number of layers. The ANN is encoded in a class, and is fed a dictionary of your choices for activation functions and loss functions, as well as a list of the neurons in each layer, for example a two layer network with 100 and 50, respectively, is fed as [100,50].\n",
    "\n",
    "Then, the easiest way to search for effective parameters sets is to use RunOne or RunTwo. RunOne will train a one layer NN across the list of options you feed it, then test its accuracy. For example, [10,20,30] will train with 10 neurons, 20 neurons, 30 neurons, and spit out the accuracy for each. Similarly, RunTwo trains in a list of two lists, the first for the number of neurons in the first layer and the second for the second layer. It will train across all combinations and sit out a matrix of accuracies.\n",
    "\n",
    "Then, once you've identified a good parameter set, use the solitary Train function grouped with RunOne and RunTwo in order to train one a specific parameter set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def read_dataset(feature_file, label_file):\n",
    "    ''' Read data set in *.csv to data frame in Pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (features)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def normalize_features(X_train, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler #import libaray\n",
    "    scaler = StandardScaler() # call an object function\n",
    "    scaler.fit(X_train) # calculate mean, std in X_train\n",
    "    X_train_norm = scaler.transform(X_train) # apply normalization on X_train\n",
    "    X_test_norm = scaler.transform(X_test) # we use the same normalization on X_test\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "\n",
    "def one_hot_encoder(y_train, y_test):\n",
    "    ''' convert label to a vector under one-hot-code fashion '''\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    y_train_ohe = lb.transform(y_train)\n",
    "    y_test_ohe = lb.transform(y_test)\n",
    "    return y_train_ohe, y_test_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "X_train_digits, y_train_digits = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test_digits, y_test_digits = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "X_train_norm_digits, X_test_norm_digits = normalize_features(X_train_digits, X_test_digits)\n",
    "y_train_ohe_digits, y_test_ohe_digits = one_hot_encoder(y_train_digits, y_test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW IS TESTING! DIVE IN; THE WATER'S FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFilter:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"convolution\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_filt = info.dimensions[0]\n",
    "        self.num_ch = info.dimensions[1]\n",
    "        self.f_i = info.dimensions[2]\n",
    "        self.f_j = info.dimensions[3]\n",
    "        self.weight = self.FInitializeFilter()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j\n",
    "        self.activation = info.activation        \n",
    "    def FInitializeFilter(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.dimensions))),size=self.dimensions)\n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.num_filt))),size=(1,self.num_filt))\n",
    "    \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.f_i)/self.stride_i) + 1)\n",
    "        out_j = int(np.ceil((imag_j - self.f_j)/self.stride_j) + 1)\n",
    "        z = np.zeros((num_imag, self.num_filt, out_i, out_j))\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                f_y_end = self.f_j\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y\n",
    "                    f_x_end = self.f_i\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x\n",
    "                        z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*self.weight[curr_f,:,0:f_x_end,0:f_y_end]) + self.bias[0][curr_f]\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,imag_in):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag,num_ch,imag_i,imag_j))\n",
    "        dfilt = np.zeros(self.weight.shape)\n",
    "        dbias = np.zeros((1,self.num_filt))\n",
    "\n",
    "        for i in range(len(imag_in[0])):\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = out_y = 0\n",
    "                f_y_end = self.f_i\n",
    "                while(curr_y + self.f_j < imag_j + 1):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y\n",
    "                    f_x_end = self.f_j\n",
    "                    while(curr_x + self.f_i < imag_i + 1): \n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_i\n",
    "                        dout[i,:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[i,curr_f, out_x, out_y] * self.weight[curr_f,:,:f_x_end,:f_y_end]\n",
    "                        dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[i,curr_f,out_x,out_y] * imag_in[i,:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "                dbias[0][curr_f] += np.sum(dprev[i,curr_f])\n",
    "\n",
    "        return dout,dfilt,dbias\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Filter Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  num_filt:\",self.num_filt)\n",
    "        print(\"  num_ch:\",self.num_ch)\n",
    "        print(\"  f_i:\",self.f_i)\n",
    "        print(\"  f_j:\",self.f_j)\n",
    "        print(\"  stride_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "        print(\"  act.f:\",self.activation.f)\n",
    "        print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  filt:\\n\",self.weight)\n",
    "        print(\"  bias:\\n\",self.bias)\n",
    "\n",
    "class CPool:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"pool\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_ch = info.dimensions[0]\n",
    "        self.pool_i = info.dimensions[1]\n",
    "        self.pool_j = info.dimensions[2]\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j  \n",
    "        \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the pool does not match the number of channels in the input!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.pool_i)/self.stride_i)) + 1\n",
    "        out_j = int(np.ceil((imag_j - self.pool_j)/self.stride_j)) + 1\n",
    "        z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_chan in range(self.num_ch):\n",
    "                curr_y = out_y = 0\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        current_y_end = imag_j\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan, curr_x:curr_x_end, curr_y:curr_y_end])\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,z\n",
    "\n",
    "    def FFeedBack(self, dprev, imag_in):\n",
    "        (num_imag_p, num_ch_p, dp_i, dp_j) = dprev.shape\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(num_ch_p != num_ch):\n",
    "            print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag, num_ch,imag_i,imag_j))\n",
    "        for i in range(imag_in.shape[0]):\n",
    "            for curr_ch in range(num_ch):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                while(out_y < dp_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                    while(out_x < dp_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        (a,b) = np.unravel_index(np.nanargmax(imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                        dout[i,curr_ch,curr_x+a,curr_y+b] = dprev[i,curr_ch,out_x,out_y]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "        return dout\n",
    "\n",
    "\n",
    "    \n",
    "    def FPrint(self):\n",
    "        print(\"Pool Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  pool_i:\",self.pool_i)\n",
    "        print(\"  pool_j:\",self.pool_j)\n",
    "        print(\"  stide_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "\n",
    "class CConnection:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"connection\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.neurons_in = info.dimensions[0]\n",
    "        self.neurons_out = info.dimensions[1]\n",
    "        self.weight = self.FInitializeWeights()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.activation = info.activation\n",
    "   \n",
    "    def FInitializeWeights(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.dimensions))),size=self.dimensions)\n",
    "       \n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.neurons_out))),size=(1,self.neurons_out))\n",
    "\n",
    "    def FFeedForward(self,images):\n",
    "        z = images.dot(self.weight) + self.bias\n",
    "        return z, self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,data_in):\n",
    "        dW = self.activation.f(data_in).T.dot(dprev)\n",
    "        db = np.sum(dprev,axis=0,keepdims=True)\n",
    "        dout = dprev.dot(self.weight.T)*self.activation.d(data_in)\n",
    "        return dout, dW, db\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Connection Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  neurons_in:\",self.neurons_in)\n",
    "        print(\"  neurons_out:\",self.neurons_out)\n",
    "        print(\"  act.f:\",self.activation.f)\n",
    "        print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  weights:\\n\",self.weight)\n",
    "        print(\"  bais:\\n\",self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLinear(X):\n",
    "    return X\n",
    "def FRELU(X):\n",
    "    a = np.copy(X)\n",
    "    a[X<0]=0\n",
    "    return a\n",
    "def FRELU_dx(X):\n",
    "    dx = np.zeros(X.shape)\n",
    "    dx[X>0] = 1\n",
    "    return dx\n",
    "\n",
    "def RegularizedLoss(y,yhat,regularization_parameter,C):\n",
    "    loss = 0\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    hinge[hinge<0]=0\n",
    "    loss = np.sum(hinge)\n",
    "    loss *= regularization_parameter\n",
    "    temp = 0\n",
    "    for item in C:\n",
    "        for elem in item:\n",
    "            temp += np.sum(elem*elem)\n",
    "    return loss + np.sqrt(temp)\n",
    "\n",
    "def RegularizedLoss_dx(y,yhat,regularization_parameter):\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "    loss = np.zeros(y.shape)\n",
    "    for i in range(hinge.shape[0]):\n",
    "        if(hinge[i]>0):\n",
    "            loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "    loss *= regularization_parameter\n",
    "    return loss\n",
    "\n",
    "def softmax(z):\n",
    "    exp_value = np.exp(z-np.amax(z, axis=1, keepdims=True)) # for stablility\n",
    "    # keepdims = True means that the output's dimension is the same as of z\n",
    "    softmax_scores = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
    "    return softmax_scores\n",
    "def accuracy(ypred, yexact):\n",
    "    p = np.array(ypred == yexact, dtype = int)\n",
    "    return np.sum(p)/float(len(yexact))\n",
    "\n",
    "class CActivation:\n",
    "    def __init__(self,Function,Derivative):\n",
    "        self.f = Function\n",
    "        self.d = Derivative\n",
    "\n",
    "RELU  = CActivation(FRELU,FRELU_dx)\n",
    "class CLayer:\n",
    "    def __init__(self,Tag,Info):\n",
    "        self.tag = Tag\n",
    "        self.info = Info\n",
    "        self.indim = None\n",
    "        self.outdim = None\n",
    "        \n",
    "class CInfo:\n",
    "    def __init__(self,dimensions=None,stride_i=1,stride_j=1,activation=RELU):\n",
    "        self.dimensions = dimensions\n",
    "        self.stride_i = stride_i\n",
    "        self.stride_j = stride_j\n",
    "        self.activation = activation\n",
    "    def FAddDimensions(self,Dimensions):\n",
    "        self.dimensions = Dimensions\n",
    "    def FAddStride(self,Stride_i=1,Stride_j=1):\n",
    "        self.stride_i = Stride_i\n",
    "        self.stride_j = Stride_j\n",
    "    def FAddActivation(self,Activation):\n",
    "        self.activation = Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, indim, LayersInfo, lr=0.1, rp=0.1):\n",
    "        self.samples = indim[0]\n",
    "        self.in_ch = []\n",
    "        self.indim_i = []\n",
    "        self.indim_j = []\n",
    "        self.in_ch.append(indim[1])\n",
    "        self.indim_i.append(indim[2])\n",
    "        self.indim_j.append(indim[3])\n",
    "\n",
    "        #self.X = X\n",
    "        #self.X_reshape = self.X.reshape(self.samples,self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        #self.y = y\n",
    "        self.lr = lr\n",
    "        self.rp = rp\n",
    "        self.probability = softmax\n",
    "\n",
    "        self.layer = []\n",
    "        for Layer in LayersInfo:\n",
    "            self.layer.append(self.FAddLayer(Layer))\n",
    "        outinfo = CInfo([-1,10])\n",
    "        finallayer = CLayer('connection',outinfo)\n",
    "        self.layer.append(self.FAddLayer(finallayer))\n",
    "            \n",
    "\n",
    "    def FAddLayer(self,Layer):\n",
    "        if(Layer.tag=='convolution'):\n",
    "            Layer.info.dimensions[1] = self.in_ch[-1]\n",
    "            self.in_ch.append(Layer.info.dimensions[0])\n",
    "            f_i = Layer.info.dimensions[2]\n",
    "            f_j = Layer.info.dimensions[3]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.indim_i.append(int(np.ceil((indim_i - f_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - f_j)/stride_j) + 1))\n",
    "            return CFilter(Layer.info)\n",
    "        elif(Layer.tag=='pool'):\n",
    "            Layer.info.dimensions[0] = self.in_ch[-1]\n",
    "            p_i = Layer.info.dimensions[1]\n",
    "            p_j = Layer.info.dimensions[2]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.in_ch.append(self.in_ch[-1])\n",
    "            self.indim_i.append(int(np.ceil((indim_i - p_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - p_j)/stride_j) + 1))\n",
    "            return CPool(Layer.info)\n",
    "        elif(Layer.tag=='connection'):\n",
    "            flatten = self.in_ch[-1]*self.indim_i[-1]*self.indim_j[-1]\n",
    "            Layer.info.dimensions[0] = flatten\n",
    "            self.in_ch.append(1)\n",
    "            self.indim_i.append(1)\n",
    "            self.indim_j.append(Layer.info.dimensions[1])\n",
    "            return CConnection(Layer.info)\n",
    "        else:\n",
    "            print(Layer.tag,'is not a valid layer option. Double check initialization.')\n",
    "            return None\n",
    "\n",
    "    def FPrint(self):\n",
    "        for l in self.layer:\n",
    "            l.FPrint()\n",
    "\n",
    "    def FFeedForward(self,X):\n",
    "        self.z = []\n",
    "        self.f = []\n",
    "        images = X.reshape(X.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        self.f.append(images)\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            self.z.append(Z)\n",
    "            if(i != len(self.layer) -1):\n",
    "                self.f.append(F)\n",
    "            images = self.f[-1]\n",
    "        self.yhat = self.probability(self.z[-1])\n",
    "        \n",
    "    def FBackPropagation(self,y):\n",
    "        d = []\n",
    "        d.insert(0,self.Loss_dx(y,self.yhat))\n",
    "        for i in range(len(self.layer)):\n",
    "            images = self.f[-1-i]\n",
    "            if(self.layer[-1-i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            elif((i < len(self.layer) - 1) and (self.layer[-1-i+1].tag == 'connection')):\n",
    "                d[0] = np.reshape(d[0],(images.shape[0],self.in_ch[-1-i],self.indim_i[-1-i],self.indim_j[-1-i]))\n",
    "            if(self.layer[-1-i].tag != 'pool'):\n",
    "                dout,dW,db = self.layer[-1-i].FFeedBack(d[0],images)\n",
    "                dW /= float(len(y))\n",
    "                db /= float(len(y))\n",
    "                \n",
    "                self.layer[-1-i].weight -= self.lr*dW\n",
    "                if(self.layer[-1-i].weight.all()!=0):\n",
    "                    self.layer[-1-i].weight -= self.rp*self.layer[-1-i].weight/np.sqrt(np.sum(self.layer[-1-i].weight*self.layer[-1-i].weight))\n",
    "                \n",
    "                self.layer[-1-i].bias -= self.lr*db\n",
    "                if(self.layer[-1-i].bias.all()!=0):\n",
    "                    self.layer[-1-i].bias -= self.rp*self.layer[-1-i].bias/np.sqrt(np.sum(self.layer[-1-i].bias*self.layer[-1-i].bias))   \n",
    "            else:\n",
    "                dout = self.layer[-1-i].FFeedBack(d[0],self.f[-1-i])\n",
    "                \n",
    "            d.insert(0,dout)\n",
    "    def Loss(self,y,yhat):\n",
    "        loss = 0\n",
    "        hinge = 1 - y*yhat\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        hinge[hinge<0]=0\n",
    "        loss = np.sum(hinge)\n",
    "        loss *= self.rp\n",
    "        temp = 0\n",
    "        for l in self.layer:\n",
    "            if(l.tag != 'pool'):\n",
    "                temp += np.sum(l.weight*l.weight)\n",
    "                temp += np.sum(l.bias*l.bias)\n",
    "        return loss + np.sqrt(temp)\n",
    "    def Loss_dx(self,y,yhat):\n",
    "        hinge = 1 - y*yhat\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "        loss = np.zeros(y.shape)\n",
    "        for i in range(hinge.shape[0]):\n",
    "            if(hinge[i]>0):\n",
    "                loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "        loss *= self.rp\n",
    "        return loss   \n",
    "    \n",
    "    def FPredict(self, X_test):\n",
    "        images = X_test.reshape(X_test.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            images = F\n",
    "        yhat = self.probability(Z)\n",
    "        # the rest is similar to the logistic regression\n",
    "        labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        num_test_samples = X_test.shape[0]\n",
    "        # find which index gives us the highest probability\n",
    "        ypred = np.zeros(num_test_samples, dtype=int)\n",
    "        for i in range(num_test_samples):\n",
    "            ypred[i] = labels[np.argmax(yhat[i,:])]\n",
    "        return ypred\n",
    "\n",
    "    def FTrain(self,epochs,batch_size,X,y):\n",
    "        batches = int(np.ceil(float(X.shape[0])/float(batch_size)))\n",
    "        for i in range(epochs):\n",
    "            np.random.shuffle(X)\n",
    "            for j in range(batches):\n",
    "                start = j*batch_size\n",
    "                end = start + batch_size\n",
    "                if(end > X.shape[0]):\n",
    "                    end = X.shape[0]\n",
    "                Xbatch = X[start:end]\n",
    "                ybatch = y[start:end]\n",
    "                self.FFeedForward(Xbatch)\n",
    "                self.FBackPropagation(ybatch)\n",
    "            if((i+1)%(int(epochs*0.1))==0):\n",
    "                print('Epoch %d of %d finished...'%(i+1,epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 100 finished...\n",
      "Epoch 20 of 100 finished...\n",
      "Epoch 30 of 100 finished...\n",
      "Epoch 40 of 100 finished...\n",
      "Epoch 50 of 100 finished...\n",
      "Epoch 60 of 100 finished...\n",
      "Epoch 70 of 100 finished...\n",
      "Epoch 80 of 100 finished...\n",
      "Epoch 90 of 100 finished...\n",
      "Epoch 100 of 100 finished...\n",
      "loss: 2025.1107098166665\n",
      "acc: 10.888889%\n",
      "401\n",
      "450\n",
      "loss: 17915.210709816667\n",
      "acc: 9.725316%\n",
      "1216\n",
      "1347\n"
     ]
    }
   ],
   "source": [
    "Xtr = X_train_norm_digits\n",
    "ytr = y_train_ohe_digits\n",
    "Xte = X_test_norm_digits\n",
    "yte = y_test_ohe_digits\n",
    "ytrain = y_train_digits\n",
    "ytest = y_test_digits\n",
    "\n",
    "samples = X.shape[0]\n",
    "filt_info = CInfo([8,-1,3,3])\n",
    "pool_info = CInfo([-1,2,2],2,2)\n",
    "conn_info = CInfo([-1,50])\n",
    "filt = CLayer('convolution',filt_info)\n",
    "pool = CLayer('pool',pool_info)\n",
    "conn = CLayer('connection',conn_info)\n",
    "cnn = CNN([samples,1,8,8],[conn])\n",
    "\n",
    "cnn.FTrain(100,100,Xtr,ytr)\n",
    "ypred = cnn.FPredict(Xte)\n",
    "print('loss:',cnn.Loss(ytest,ypred))\n",
    "print('acc: %f%%'%(100*accuracy(ytest.ravel(),ypred.ravel())))\n",
    "SUM = 0\n",
    "for i in range(len(ypred)):\n",
    "    if(ypred[i]!=ytest[i]):\n",
    "        SUM += 1\n",
    "print(SUM)\n",
    "print(len(ytest))\n",
    "ypred = cnn.FPredict(Xtr)\n",
    "print('loss:',cnn.Loss(ytrain,ypred))\n",
    "print('acc: %f%%'%(100*accuracy(ytrain.ravel(),ypred.ravel())))\n",
    "SUM = 0\n",
    "for i in range(len(ypred)):\n",
    "    if(ypred[i]!=ytrain[i]):\n",
    "        SUM += 1\n",
    "print(SUM)\n",
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\ndef InitializeFilter(dimensions):\\n    return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(dimensions))),size=dimensions)\\n\\n\\ndef Convolution(images, filt, bias, activat, stride_i=1,stride_j=1):\\n    (num_filt, num_ch_f, f_i, f_j) = filt.shape\\n    (num_imag, num_ch, imag_i, imag_j) = images.shape\\n    \\n    if(num_ch_f != num_ch):\\n        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\\n\\n    out_i = int(np.ceil((imag_i - f_i)/stride_i) + 1)\\n    out_j = int(np.ceil((imag_j - f_j)/stride_j) + 1)\\n    z = np.zeros((num_imag, num_filt, out_i, out_j))\\n    i=0\\n    for image in images:\\n        for curr_f in range(num_filt):\\n            curr_y = curr_y_end = out_y = 0\\n            f_y_end = f_j + 1\\n            while(out_y < out_j):\\n                curr_x = curr_x_end = out_x = 0\\n                curr_y_end = curr_y + f_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                    f_y_end = curr_y_end - curr_y\\n                f_x_end = f_i + 1\\n                while(out_x < out_i):\\n                    curr_x_end = curr_x + f_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                        f_x_end = curr_x_end - curr_x\\n                    z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + bias[curr_f]\\n                    curr_x += stride_i\\n                    out_x += 1\\n                curr_y += stride_j\\n                out_y += 1\\n        i+=1\\n    return z,activat(z)\\n\\ndef FMaxPool(images,pool_i=2,pool_j=2,stride_i=2,stride_j=2):\\n    (num_imag, num_ch, imag_i, imag_j) = images.shape\\n\\n    out_i = int(np.ceil((imag_i - pool_i)/stride_i)) + 1\\n    out_j = int(np.ceil((imag_j - pool_j)/stride_j)) + 1\\n    z = np.zeros((num_imag, num_ch, out_i, out_j))\\n    index = np.zeros((num_imag, num_ch, out_i, out_j))\\n    \\n    i=0\\n    for image in images:\\n        for curr_chan in range(num_ch):\\n            curr_y = out_y = 0\\n            while(out_y < out_j):\\n                curr_x = out_x = 0\\n                curr_y_end = curr_y + pool_j\\n                if(curr_y_end > imag_j):\\n                    current_y_end = imag_j\\n                while(out_x < out_i):\\n                    curr_x_end = curr_x + pool_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                    z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\\n                    index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\\n                    curr_x += stride_i\\n                    out_x +=1\\n                curr_y += stride_j\\n                out_y += 1\\n        i+=1\\n    return z,index\\n\\ndef FConnection(images,weights,bias,activation):\\n    z = images.dot(weights) + bias\\n    return z, activation(z)\\n\\ndef FbackConvolution(dprev,conv_in,filt,derivative,stride_i=1,stride_j=1):\\n    (num_filt, num_ch_f, f_i, f_j) = filt.shape\\n    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\\n    \\n    if(num_ch_f != num_ch):\\n        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\\n\\n    dout = np.zeros((num_ch,imag_i,imag_j))\\n    dfilt = np.zeros(filt.shape)\\n    dbias = np.zeros((num_filt,1))\\n    \\n    for conv in conv_in:\\n        dout_conv = np.zeros((num_ch,imag_i,imag_j))\\n        for curr_f in range(num_filt):\\n            curr_y = out_y = 0\\n            f_y_end = f_i\\n            while(curr_y + f_j < imag_j + 1):\\n                curr_x = out_x = 0\\n                curr_y_end = curr_y + f_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                    f_y_end = curr_y_end - curr_y\\n                f_x_end = f_j\\n                while(curr_x + f_i < imag_i + 1): \\n                    curr_x_end = curr_x + f_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                        f_x_end = curr_x_end - curr_i\\n                    dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\\n                    dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\\n\\n                    curr_x += stride_i\\n                    out_x +=1\\n                curr_y += stride_j\\n                out_y += 1\\n            dbias[curr_f] = np.sum(dprev[curr_f])\\n        dout += dout_conv*derivative(conv)\\n\\n    return dout,dfilt,dbias\\n\\ndef FbackMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2):\\n    (num_ch_p, dp_i, dp_j) = dpool.shape\\n    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\\n    \\n    if(num_ch_p != num_ch):\\n        print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\\n\\n    dout = np.zeros((num_ch,imag_i,imag_j))\\n    \\n    for conv in conv_in:\\n        for curr_ch in range(num_ch):\\n            curr_y = curr_y_end = out_y = 0\\n            while(out_y < dp_j):\\n                curr_x = curr_x_end = out_x = 0\\n                curr_y_end = curr_y + p_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                while(out_x < dp_i):\\n                    curr_x_end = curr_x + p_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                    (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\\n                    dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\\n\\n                    curr_x += stride_i\\n                    out_x += 1\\n                curr_y += stride_j\\n                out_y += 1\\n    return dout\\n\\ndef FbackConnection(dprev,data_in,weight,activation,derivative):\\n    dW = activation(data_in).T.dot(dprev)\\n    db = np.sum(dprev,axis=0,keepdims=True)\\n    dout = dprev.dot(weight.T)*derivative(data_in)\\n    return dout, dW, db\\n    \\n#def Convolution(images, filt, bias, activation, stride_i=1,stride_j=1):\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "def InitializeFilter(dimensions):\n",
    "    return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(dimensions))),size=dimensions)\n",
    "\n",
    "\n",
    "def Convolution(images, filt, bias, activat, stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - f_i)/stride_i) + 1)\n",
    "    out_j = int(np.ceil((imag_j - f_j)/stride_j) + 1)\n",
    "    z = np.zeros((num_imag, num_filt, out_i, out_j))\n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            f_y_end = f_j + 1\n",
    "            while(out_y < out_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_i + 1\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_x\n",
    "                    z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + bias[curr_f]\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,activat(z)\n",
    "\n",
    "def FMaxPool(images,pool_i=2,pool_j=2,stride_i=2,stride_j=2):\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - pool_i)/stride_i)) + 1\n",
    "    out_j = int(np.ceil((imag_j - pool_j)/stride_j)) + 1\n",
    "    z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    index = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    \n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_chan in range(num_ch):\n",
    "            curr_y = out_y = 0\n",
    "            while(out_y < out_j):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + pool_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    current_y_end = imag_j\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + pool_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,index\n",
    "\n",
    "def FConnection(images,weights,bias,activation):\n",
    "    z = images.dot(weights) + bias\n",
    "    return z, activation(z)\n",
    "\n",
    "def FbackConvolution(dprev,conv_in,filt,derivative,stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dbias = np.zeros((num_filt,1))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        dout_conv = np.zeros((num_ch,imag_i,imag_j))\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = out_y = 0\n",
    "            f_y_end = f_i\n",
    "            while(curr_y + f_j < imag_j + 1):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_j\n",
    "                while(curr_x + f_i < imag_i + 1): \n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_i\n",
    "                    dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\n",
    "                    dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "            dbias[curr_f] = np.sum(dprev[curr_f])\n",
    "        dout += dout_conv*derivative(conv)\n",
    "\n",
    "    return dout,dfilt,dbias\n",
    "\n",
    "def FbackMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2):\n",
    "    (num_ch_p, dp_i, dp_j) = dpool.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_p != num_ch):\n",
    "        print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        for curr_ch in range(num_ch):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            while(out_y < dp_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + p_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                while(out_x < dp_i):\n",
    "                    curr_x_end = curr_x + p_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                    dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "    return dout\n",
    "\n",
    "def FbackConnection(dprev,data_in,weight,activation,derivative):\n",
    "    dW = activation(data_in).T.dot(dprev)\n",
    "    db = np.sum(dprev,axis=0,keepdims=True)\n",
    "    dout = dprev.dot(weight.T)*derivative(data_in)\n",
    "    return dout, dW, db\n",
    "    \n",
    "#def Convolution(images, filt, bias, activation, stride_i=1,stride_j=1):\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
