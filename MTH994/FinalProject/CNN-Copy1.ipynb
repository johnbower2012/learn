{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Here I've coded an artificial neural network with an arbitrary number of layers. The ANN is encoded in a class, and is fed a dictionary of your choices for activation functions and loss functions, as well as a list of the neurons in each layer, for example a two layer network with 100 and 50, respectively, is fed as [100,50].\n",
    "\n",
    "Then, the easiest way to search for effective parameters sets is to use RunOne or RunTwo. RunOne will train a one layer NN across the list of options you feed it, then test its accuracy. For example, [10,20,30] will train with 10 neurons, 20 neurons, 30 neurons, and spit out the accuracy for each. Similarly, RunTwo trains in a list of two lists, the first for the number of neurons in the first layer and the second for the second layer. It will train across all combinations and sit out a matrix of accuracies.\n",
    "\n",
    "Then, once you've identified a good parameter set, use the solitary Train function grouped with RunOne and RunTwo in order to train one a specific parameter set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def read_dataset(feature_file, label_file):\n",
    "    ''' Read data set in *.csv to data frame in Pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (features)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def normalize_features(X_train, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler #import libaray\n",
    "    scaler = StandardScaler() # call an object function\n",
    "    scaler.fit(X_train) # calculate mean, std in X_train\n",
    "    X_train_norm = scaler.transform(X_train) # apply normalization on X_train\n",
    "    X_test_norm = scaler.transform(X_test) # we use the same normalization on X_test\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "\n",
    "def one_hot_encoder(y_train, y_test):\n",
    "    ''' convert label to a vector under one-hot-code fashion '''\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    y_train_ohe = lb.transform(y_train)\n",
    "    y_test_ohe = lb.transform(y_test)\n",
    "    return y_train_ohe, y_test_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "X_train_digits, y_train_digits = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test_digits, y_test_digits = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "X_train_norm_digits, X_test_norm_digits = normalize_features(X_train_digits, X_test_digits)\n",
    "y_train_ohe_digits, y_test_ohe_digits = one_hot_encoder(y_train_digits, y_test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW IS TESTING! DIVE IN; THE WATER'S FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFilter:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"convolution\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_filt = info.dimensions[0]\n",
    "        self.num_ch = info.dimensions[1]\n",
    "        self.f_i = info.dimensions[2]\n",
    "        self.f_j = info.dimensions[3]\n",
    "        self.weight = self.FInitializeFilter()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j\n",
    "        self.activation = info.activation        \n",
    "    def FInitializeFilter(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.dimensions))),size=self.dimensions)\n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.num_filt))),size=(1,self.num_filt))\n",
    "    \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.f_i)/self.stride_i) + 1)\n",
    "        out_j = int(np.ceil((imag_j - self.f_j)/self.stride_j) + 1)\n",
    "        z = np.zeros((num_imag, self.num_filt, out_i, out_j))\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                f_y_end = self.f_j\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y\n",
    "                    f_x_end = self.f_i\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x\n",
    "                        z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*self.weight[curr_f,:,0:f_x_end,0:f_y_end]) + self.bias[0][curr_f]\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,imag_in):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag,num_ch,imag_i,imag_j))\n",
    "        dfilt = np.zeros(self.weight.shape)\n",
    "        dbias = np.zeros((1,self.num_filt))\n",
    "\n",
    "        for i in range(imag_in.shape[0]):\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = out_y = 0\n",
    "                f_y_end = self.f_i\n",
    "                while(curr_y + self.f_j < imag_j + 1):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y + 1\n",
    "                    f_x_end = self.f_j\n",
    "                    while(curr_x + self.f_i < imag_i + 1): \n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x + 1                      \n",
    "                        dout[i,:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[i,curr_f, out_x, out_y] * self.weight[curr_f,:,:f_x_end,:f_y_end]\n",
    "                        dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[i,curr_f,out_x,out_y] * imag_in[i,:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "                dbias[0][curr_f] += np.sum(dprev[i,curr_f])\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('imag_in\\n',imag_in) \n",
    "        print('dfilt\\n',dfilt)\n",
    "        print('dbias\\n',dbias)\n",
    "        '''\n",
    "        return dout,dfilt,dbias\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Filter Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  num_filt:\",self.num_filt)\n",
    "        print(\"  num_ch:\",self.num_ch)\n",
    "        print(\"  f_i:\",self.f_i)\n",
    "        print(\"  f_j:\",self.f_j)\n",
    "        print(\"  stride_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "        #print(\"  act.f:\",self.activation.f)\n",
    "        #print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  filt:\\n\",self.weight)\n",
    "        print(\"  bias:\\n\",self.bias)\n",
    "\n",
    "class CPool:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"pool\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_ch = info.dimensions[0]\n",
    "        self.pool_i = info.dimensions[1]\n",
    "        self.pool_j = info.dimensions[2]\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j  \n",
    "        \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the pool does not match the number of channels in the input!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.pool_i)/self.stride_i)) + 1\n",
    "        out_j = int(np.ceil((imag_j - self.pool_j)/self.stride_j)) + 1\n",
    "        z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_chan in range(self.num_ch):\n",
    "                curr_y = out_y = 0\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        current_y_end = imag_j\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan, curr_x:curr_x_end, curr_y:curr_y_end])\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,z\n",
    "\n",
    "    def FFeedBack(self, dprev, imag_in):\n",
    "        (num_imag_p, num_ch_p, dp_i, dp_j) = dprev.shape\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(num_ch_p != num_ch):\n",
    "            print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag, num_ch,imag_i,imag_j))\n",
    "        for i in range(imag_in.shape[0]):\n",
    "            for curr_ch in range(num_ch):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                while(out_y < dp_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                    while(out_x < dp_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        (a,b) = np.unravel_index(np.nanargmax(imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                        dout[i,curr_ch,curr_x+a,curr_y+b] += dprev[i,curr_ch,out_x,out_y]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('imag_in\\n',imag_in)\n",
    "        '''\n",
    "        return dout\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Pool Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  pool_i:\",self.pool_i)\n",
    "        print(\"  pool_j:\",self.pool_j)\n",
    "        print(\"  stide_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "\n",
    "class CConnection:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"connection\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.neurons_in = info.dimensions[0]\n",
    "        self.neurons_out = info.dimensions[1]\n",
    "        self.weight = self.FInitializeWeights()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.activation = info.activation\n",
    "   \n",
    "    def FInitializeWeights(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod([self.neurons_in,self.neurons_out]))),size=[self.neurons_in,self.neurons_out])\n",
    "       \n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.neurons_out))),size=(1,self.neurons_out))\n",
    "\n",
    "    def FFeedForward(self,images):\n",
    "        z = images.dot(self.weight) + self.bias\n",
    "        return z, self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,data_in):\n",
    "        dW = self.activation.f(data_in).T.dot(dprev)\n",
    "        db = np.sum(dprev,axis=0,keepdims=True)\n",
    "        dout = dprev.dot(self.weight.T)*self.activation.d(data_in)\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('f(data)\\n',self.activation.f(data_in))\n",
    "        print('d(data)\\n',self.activation.d(data_in))\n",
    "        print('weight\\n',self.weight)\n",
    "        print('bias\\n',self.bias)\n",
    "        print('dW\\n',dW)\n",
    "        print('db\\n',db)\n",
    "        '''\n",
    "        return dout, dW, db\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Connection Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  neurons_in:\",self.neurons_in)\n",
    "        print(\"  neurons_out:\",self.neurons_out)\n",
    "        #print(\"  act.f:\",self.activation.f)\n",
    "        #print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  weights:\\n\",self.weight)\n",
    "        print(\"  bias:\\n\",self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLinear(X):\n",
    "    return X\n",
    "def FRELU(X):\n",
    "    a = np.copy(X)\n",
    "    a[X<0]=0\n",
    "    return a\n",
    "def FRELU_dx(X):\n",
    "    dx = np.zeros(X.shape)\n",
    "    dx[X>0] = 1\n",
    "    return dx\n",
    "\n",
    "def RegularizedLoss(y,yhat,regularization_parameter,C):\n",
    "    loss = 0\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    hinge[hinge<0]=0\n",
    "    loss = np.sum(hinge)\n",
    "    loss *= regularization_parameter\n",
    "    temp = 0\n",
    "    for item in C:\n",
    "        for elem in item:\n",
    "            temp += np.sum(elem*elem)\n",
    "    return loss + np.sqrt(temp)\n",
    "\n",
    "def RegularizedLoss_dx(y,yhat,regularization_parameter):\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "    loss = np.zeros(y.shape)\n",
    "    for i in range(hinge.shape[0]):\n",
    "        if(hinge[i]>0):\n",
    "            loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "    loss *= regularization_parameter\n",
    "    return loss\n",
    "\n",
    "def softmax(z):\n",
    "    exp_value = np.exp(z-np.amax(z, axis=1, keepdims=True)) # for stablility\n",
    "    # keepdims = True means that the output's dimension is the same as of z\n",
    "    softmax_scores = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
    "    return softmax_scores\n",
    "def accuracy(ypred, yexact):\n",
    "    p = np.array(ypred == yexact, dtype = int)\n",
    "    return np.sum(p)/float(len(yexact))\n",
    "\n",
    "class CActivation:\n",
    "    def __init__(self,Function,Derivative):\n",
    "        self.f = Function\n",
    "        self.d = Derivative\n",
    "\n",
    "RELU  = CActivation(FRELU,FRELU_dx)\n",
    "class CLayer:\n",
    "    def __init__(self,Tag,Info):\n",
    "        self.tag = Tag\n",
    "        self.info = Info\n",
    "        self.indim = None\n",
    "        self.outdim = None\n",
    "        \n",
    "class CInfo:\n",
    "    def __init__(self,dimensions=None,stride_i=1,stride_j=1,activation=RELU):\n",
    "        self.dimensions = dimensions\n",
    "        self.stride_i = stride_i\n",
    "        self.stride_j = stride_j\n",
    "        self.activation = activation\n",
    "    def FAddDimensions(self,Dimensions):\n",
    "        self.dimensions = Dimensions\n",
    "    def FAddStride(self,Stride_i=1,Stride_j=1):\n",
    "        self.stride_i = Stride_i\n",
    "        self.stride_j = Stride_j\n",
    "    def FAddActivation(self,Activation):\n",
    "        self.activation = Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, indim, outdim, LayersInfo, lr=0.1, rp=0.1):\n",
    "        self.in_ch = []\n",
    "        self.indim_i = []\n",
    "        self.indim_j = []\n",
    "        self.in_ch.append(indim[0])\n",
    "        self.indim_i.append(indim[1])\n",
    "        self.indim_j.append(indim[1])\n",
    "        self.outdim = outdim\n",
    "\n",
    "        #self.X = X\n",
    "        #self.X_reshape = self.X.reshape(self.samples,self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        #self.y = y\n",
    "        self.lr = lr\n",
    "        self.rp = rp\n",
    "        self.probability = softmax\n",
    "\n",
    "        self.layer = []\n",
    "        for Layer in LayersInfo:\n",
    "            self.layer.append(self.FAddLayer(Layer))\n",
    "        outinfo = CInfo([-1,self.outdim])\n",
    "        finallayer = CLayer('connection',outinfo)\n",
    "        self.layer.append(self.FAddLayer(finallayer))\n",
    "            \n",
    "\n",
    "    def FAddLayer(self,Layer):\n",
    "        if(Layer.tag=='convolution'):\n",
    "            Layer.info.dimensions[1] = self.in_ch[-1]\n",
    "            self.in_ch.append(Layer.info.dimensions[0])\n",
    "            f_i = Layer.info.dimensions[2]\n",
    "            f_j = Layer.info.dimensions[3]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.indim_i.append(int(np.ceil((indim_i - f_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - f_j)/stride_j) + 1))\n",
    "            return CFilter(Layer.info)\n",
    "        elif(Layer.tag=='pool'):\n",
    "            Layer.info.dimensions[0] = self.in_ch[-1]\n",
    "            p_i = Layer.info.dimensions[1]\n",
    "            p_j = Layer.info.dimensions[2]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.in_ch.append(self.in_ch[-1])\n",
    "            self.indim_i.append(int(np.ceil((indim_i - p_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - p_j)/stride_j) + 1))\n",
    "            return CPool(Layer.info)\n",
    "        elif(Layer.tag=='connection'):\n",
    "            flatten = self.in_ch[-1]*self.indim_i[-1]*self.indim_j[-1]\n",
    "            Layer.info.dimensions[0] = flatten\n",
    "            self.in_ch.append(1)\n",
    "            self.indim_i.append(1)\n",
    "            self.indim_j.append(Layer.info.dimensions[1])\n",
    "            return CConnection(Layer.info)\n",
    "        else:\n",
    "            print(Layer.tag,'is not a valid layer option. Double check initialization.')\n",
    "            return None\n",
    "\n",
    "    def FPrint(self):\n",
    "        for l in self.layer:\n",
    "            l.FPrint()\n",
    "\n",
    "    def FFeedForward(self,X):\n",
    "        self.z = []\n",
    "        self.f = []\n",
    "        images = X.reshape(X.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        self.f.append(images)\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            self.z.append(Z)\n",
    "            if(i != len(self.layer) -1):\n",
    "                self.f.append(F)\n",
    "            images = self.f[-1]\n",
    "            '''\n",
    "            print('')\n",
    "            print(self.layer[i].FPrint())\n",
    "            print('z',Z)\n",
    "            print('f',F)\n",
    "            '''\n",
    "        self.yhat = self.probability(self.z[-1])\n",
    "        \n",
    "    def FBackPropagation(self,y):\n",
    "        d = []\n",
    "        d.insert(0,self.Loss_dx(y,self.yhat)) \n",
    "        #print('dout\\n',d[0])\n",
    "        for i in range(len(self.layer)):\n",
    "            images = self.f[-1-i]\n",
    "            if(self.layer[-1-i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            elif(self.layer[-1-i+1].tag == 'connection'):\n",
    "                d[0] = np.reshape(d[0],(images.shape[0],self.in_ch[-1-i],self.indim_i[-1-i],self.indim_j[-1-i]))\n",
    "            if(self.layer[-1-i].tag != 'pool'):\n",
    "                dout,dW,db = self.layer[-1-i].FFeedBack(d[0],images)\n",
    "                #dW /= float(len(y))\n",
    "                #db /= float(len(y))\n",
    "                self.layer[-1-i].weight = self.layer[-1-i].weight - self.lr*dW\n",
    "                if(self.rp != 0 and self.layer[-1-i].weight.all() !=0 ):\n",
    "                    self.layer[-1-i].weight = self.layer[-1-i].weight - self.rp*self.layer[-1-i].weight/np.sqrt(np.sum(self.layer[-1-i].weight*self.layer[-1-i].weight))/self.layer[-1-i].weight.size\n",
    "\n",
    "                self.layer[-1-i].bias = self.layer[-1-i].bias - self.lr*db\n",
    "                if(self.rp != 0 and self.layer[-1-i].bias.all() !=0 ):\n",
    "                    self.layer[-1-i].bias = self.layer[-1-i].bias - self.rp*self.layer[-1-i].bias/np.sqrt(np.sum(self.layer[-1-i].bias*self.layer[-1-i].bias))/self.layer[-1-i].bias.size  \n",
    "            else:\n",
    "                dout = self.layer[-1-i].FFeedBack(d[0],self.f[-1-i])\n",
    "                \n",
    "            d.insert(0,dout)\n",
    "            #print('dout\\n',d[0])\n",
    "            \n",
    "    def Loss(self,y,yhat):\n",
    "        loss = 0\n",
    "        hinge = 1 - y*yhat\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        hinge[hinge<0]=0\n",
    "        loss = np.sum(hinge)\n",
    "        loss *= self.rp\n",
    "        temp = 0\n",
    "        for l in self.layer:\n",
    "            if(l.tag != 'pool'):\n",
    "                temp += np.sum(l.weight*l.weight)\n",
    "                temp += np.sum(l.bias*l.bias)\n",
    "        return loss + np.sqrt(temp)\n",
    "\n",
    "    def Loss_dx(self,y,yhat):\n",
    "        hinge = 1 - y*yhat\n",
    "        #print('hinge\\n',hinge)\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        #print('hinge\\n',hinge)\n",
    "        summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "        #print('summed\\n',summed)\n",
    "        loss = np.zeros(y.shape)\n",
    "        for i in range(hinge.shape[0]):\n",
    "            if(hinge[i]>0):\n",
    "                loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "        #print('dloss\\n',loss)\n",
    "        loss *= self.rp\n",
    "        #print('dloss\\n',loss)\n",
    "        return loss   \n",
    "    \n",
    "    def FPredict(self, X_test):\n",
    "        images = X_test.reshape(X_test.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        f = images\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            images = F\n",
    "        yhat = self.probability(Z)\n",
    "       \n",
    "        # the rest is similar to the logistic regression\n",
    "        labels = np.arange(0,self.outdim+1)\n",
    "        num_test_samples = X_test.shape[0]\n",
    "        # find which index gives us the highest probability\n",
    "        ypred = np.zeros(num_test_samples, dtype=int)\n",
    "        for i in range(num_test_samples):\n",
    "            ypred[i] = labels[np.argmax(yhat[i,:])]\n",
    "        return ypred\n",
    "\n",
    "    def FTrain(self,epochs,batchsize,X,y,Xtest,ytest):\n",
    "        batches = int(np.ceil(X.shape[0]/batchsize))\n",
    "        for i in range(epochs):\n",
    "            for j in range(batches):\n",
    "                start = j*batchsize\n",
    "                end = start + batchsize\n",
    "                if(end > X_train_norm.shape[0]):\n",
    "                    end = X_train_norm.shape[0]\n",
    "                X_ = X[start:end]\n",
    "                y_ = y[start:end]\n",
    "                cnn.FFeedForward(X_)\n",
    "                cnn.FBackPropagation(y_)\n",
    "                if((i+1)%(epochs/10) == 0):\n",
    "                    ypred = cnn.FPredict(Xtest)\n",
    "                    print(i+1,j,accuracy(ypred.ravel(),ytest.ravel()),'\\n  Loss: ',self.Loss(y_,self.yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 0.18 \n",
      "  Loss:  135.72351114792284\n",
      "10 1 0.19333333333333333 \n",
      "  Loss:  135.73274461715707\n",
      "10 2 0.18 \n",
      "  Loss:  135.68765087534555\n",
      "10 3 0.18222222222222223 \n",
      "  Loss:  135.7178544469635\n",
      "10 4 0.1711111111111111 \n",
      "  Loss:  135.71839596311077\n",
      "10 5 0.17777777777777778 \n",
      "  Loss:  135.69643168828463\n",
      "10 6 0.17555555555555555 \n",
      "  Loss:  135.6798152867226\n",
      "10 7 0.17333333333333334 \n",
      "  Loss:  135.79479303312942\n",
      "10 8 0.16 \n",
      "  Loss:  135.66404271123977\n",
      "10 9 0.1622222222222222 \n",
      "  Loss:  132.76739294812774\n",
      "20 0 0.8755555555555555 \n",
      "  Loss:  130.3876312952136\n",
      "20 1 0.8888888888888888 \n",
      "  Loss:  130.06534549701632\n",
      "20 2 0.8777777777777778 \n",
      "  Loss:  129.70880771301336\n",
      "20 3 0.8533333333333334 \n",
      "  Loss:  130.1454565872182\n",
      "20 4 0.8666666666666667 \n",
      "  Loss:  130.529032806332\n",
      "20 5 0.8733333333333333 \n",
      "  Loss:  129.62068865466304\n",
      "20 6 0.8911111111111111 \n",
      "  Loss:  130.28207018750686\n",
      "20 7 0.7755555555555556 \n",
      "  Loss:  130.53910139191117\n",
      "20 8 0.86 \n",
      "  Loss:  131.4584931044049\n",
      "20 9 0.8822222222222222 \n",
      "  Loss:  127.16176695619939\n",
      "30 0 0.9511111111111111 \n",
      "  Loss:  130.17373232098006\n",
      "30 1 0.9466666666666667 \n",
      "  Loss:  129.96292372971587\n",
      "30 2 0.9511111111111111 \n",
      "  Loss:  129.85013335897483\n",
      "30 3 0.9466666666666667 \n",
      "  Loss:  130.0978967544591\n",
      "30 4 0.9355555555555556 \n",
      "  Loss:  130.33156103353386\n",
      "30 5 0.9466666666666667 \n",
      "  Loss:  129.82213667657675\n",
      "30 6 0.9555555555555556 \n",
      "  Loss:  130.4506296997174\n",
      "30 7 0.9333333333333333 \n",
      "  Loss:  130.1382709164337\n",
      "30 8 0.9422222222222222 \n",
      "  Loss:  130.50616550294353\n",
      "30 9 0.9488888888888889 \n",
      "  Loss:  127.30994412653921\n",
      "40 0 0.96 \n",
      "  Loss:  130.27758295006285\n",
      "40 1 0.9577777777777777 \n",
      "  Loss:  130.30401639666474\n",
      "40 2 0.9555555555555556 \n",
      "  Loss:  130.21314574346238\n",
      "40 3 0.9577777777777777 \n",
      "  Loss:  130.48530899206264\n",
      "40 4 0.9533333333333334 \n",
      "  Loss:  130.61230353447073\n",
      "40 5 0.9555555555555556 \n",
      "  Loss:  130.25077461840243\n",
      "40 6 0.9555555555555556 \n",
      "  Loss:  130.7145146493329\n",
      "40 7 0.9577777777777777 \n",
      "  Loss:  130.44862096338827\n",
      "40 8 0.9577777777777777 \n",
      "  Loss:  130.31069019359109\n",
      "40 9 0.9577777777777777 \n",
      "  Loss:  127.63457417564561\n",
      "50 0 0.96 \n",
      "  Loss:  130.49154129521847\n",
      "50 1 0.96 \n",
      "  Loss:  130.50049145886484\n",
      "50 2 0.9622222222222222 \n",
      "  Loss:  130.48011984141348\n",
      "50 3 0.9644444444444444 \n",
      "  Loss:  130.6963335083652\n",
      "50 4 0.9644444444444444 \n",
      "  Loss:  130.78229347432324\n",
      "50 5 0.9622222222222222 \n",
      "  Loss:  130.50651218954545\n",
      "50 6 0.9622222222222222 \n",
      "  Loss:  130.91737126913333\n",
      "50 7 0.9644444444444444 \n",
      "  Loss:  130.66923238016278\n",
      "50 8 0.9644444444444444 \n",
      "  Loss:  130.5016240695162\n",
      "50 9 0.9622222222222222 \n",
      "  Loss:  127.8899681848262\n",
      "60 0 0.9666666666666667 \n",
      "  Loss:  130.64380335472973\n",
      "60 1 0.9666666666666667 \n",
      "  Loss:  130.64824923716202\n",
      "60 2 0.9644444444444444 \n",
      "  Loss:  130.64068266952367\n",
      "60 3 0.9666666666666667 \n",
      "  Loss:  130.84670648823766\n",
      "60 4 0.9688888888888889 \n",
      "  Loss:  130.935733465332\n",
      "60 5 0.9644444444444444 \n",
      "  Loss:  130.65346140807492\n",
      "60 6 0.9666666666666667 \n",
      "  Loss:  131.05907524299465\n",
      "60 7 0.9666666666666667 \n",
      "  Loss:  130.7574602699493\n",
      "60 8 0.9666666666666667 \n",
      "  Loss:  130.65289330777873\n",
      "60 9 0.9666666666666667 \n",
      "  Loss:  128.0428035458051\n",
      "70 0 0.9711111111111111 \n",
      "  Loss:  130.7541621045673\n",
      "70 1 0.9711111111111111 \n",
      "  Loss:  130.75921483486917\n",
      "70 2 0.9711111111111111 \n",
      "  Loss:  130.7522453427357\n",
      "70 3 0.9733333333333334 \n",
      "  Loss:  130.95734132385974\n",
      "70 4 0.9688888888888889 \n",
      "  Loss:  131.0447962683474\n",
      "70 5 0.9711111111111111 \n",
      "  Loss:  130.76091730036396\n",
      "70 6 0.9711111111111111 \n",
      "  Loss:  131.159445768837\n",
      "70 7 0.9733333333333334 \n",
      "  Loss:  130.8608311839962\n",
      "70 8 0.9733333333333334 \n",
      "  Loss:  130.76107372461357\n",
      "70 9 0.9711111111111111 \n",
      "  Loss:  128.06430769978346\n",
      "80 0 0.9711111111111111 \n",
      "  Loss:  130.84674694614762\n",
      "80 1 0.9711111111111111 \n",
      "  Loss:  130.8606915084226\n",
      "80 2 0.9711111111111111 \n",
      "  Loss:  130.84502743946797\n",
      "80 3 0.9733333333333334 \n",
      "  Loss:  131.0503952937913\n",
      "80 4 0.9666666666666667 \n",
      "  Loss:  131.08067994553278\n",
      "80 5 0.9688888888888889 \n",
      "  Loss:  130.85702764005993\n",
      "80 6 0.9711111111111111 \n",
      "  Loss:  131.1774126371407\n",
      "80 7 0.9711111111111111 \n",
      "  Loss:  130.9535809352378\n",
      "80 8 0.9711111111111111 \n",
      "  Loss:  130.8568963792652\n",
      "80 9 0.9688888888888889 \n",
      "  Loss:  128.154113291818\n",
      "90 0 0.9733333333333334 \n",
      "  Loss:  130.9210471189087\n",
      "90 1 0.9711111111111111 \n",
      "  Loss:  130.9273237781597\n",
      "90 2 0.9711111111111111 \n",
      "  Loss:  130.9212716767714\n",
      "90 3 0.9733333333333334 \n",
      "  Loss:  131.12595981165225\n",
      "90 4 0.9711111111111111 \n",
      "  Loss:  131.13611822045692\n",
      "90 5 0.9733333333333334 \n",
      "  Loss:  130.92773303069382\n",
      "90 6 0.9711111111111111 \n",
      "  Loss:  131.23387360720926\n",
      "90 7 0.9711111111111111 \n",
      "  Loss:  131.02550037296487\n",
      "90 8 0.9733333333333334 \n",
      "  Loss:  130.9285994461323\n",
      "90 9 0.9733333333333334 \n",
      "  Loss:  128.22598126718208\n",
      "100 0 0.9733333333333334 \n",
      "  Loss:  130.97476810041175\n",
      "100 1 0.9733333333333334 \n",
      "  Loss:  130.97818316054475\n",
      "100 2 0.9733333333333334 \n",
      "  Loss:  130.9747885370173\n",
      "100 3 0.9733333333333334 \n",
      "  Loss:  131.179668236094\n",
      "100 4 0.9733333333333334 \n",
      "  Loss:  131.18572472293775\n",
      "100 5 0.9733333333333334 \n",
      "  Loss:  130.98064741054648\n",
      "100 6 0.9711111111111111 \n",
      "  Loss:  131.27660546058112\n",
      "100 7 0.9711111111111111 \n",
      "  Loss:  131.0764616571874\n",
      "100 8 0.9733333333333334 \n",
      "  Loss:  130.9806954833372\n",
      "100 9 0.9733333333333334 \n",
      "  Loss:  128.27814847550508\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test, y_test = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "X_train_norm, X_test_norm = normalize_features(X_train_digits, X_test_digits)\n",
    "y_train_ohe, y_test_ohe = one_hot_encoder(y_train_digits, y_test_digits)\n",
    "\n",
    "\n",
    "filt_info = CInfo([8,-1,3,3])\n",
    "filt = CLayer('convolution',filt_info)\n",
    "\n",
    "pool_info = CInfo([-1,2,2],2,2)\n",
    "pool = CLayer('pool',pool_info)\n",
    "\n",
    "conn_info = CInfo([-1,100])\n",
    "conn = CLayer('connection',conn_info)\n",
    "\n",
    "cnn = CNN([1,8,8],10,[filt,pool,conn],0.05,0.1)\n",
    "epochs = 100\n",
    "batches = 10\n",
    "batchsize = int (np.ceil(X_train_norm.shape[0]/batches))\n",
    "cnn.FTrain(epochs,\\\n",
    "           batchsize,\\\n",
    "           X_train_norm,\\\n",
    "           y_train_ohe,\\\n",
    "           X_test_norm,\\\n",
    "           y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X\n",
      " [[[[-16. -15. -14. -13.]\n",
      "   [-12. -11. -10.  -9.]\n",
      "   [ -8.  -7.  -6.  -5.]\n",
      "   [ -4.  -3.  -2.  -1.]]]\n",
      "\n",
      "\n",
      " [[[  0.   1.   2.   3.]\n",
      "   [  4.  10.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]]]\n",
      "\n",
      "y\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "yhat\n",
      " [[ 0.  1. -1.]\n",
      " [ 0.  1. -1.]]\n",
      "\n",
      "Filter Information:\n",
      "  tag: convolution\n",
      "  num_filt: 2\n",
      "  num_ch: 1\n",
      "  f_i: 2\n",
      "  f_j: 2\n",
      "  stride_i: 1\n",
      "  stride_j: 1\n",
      "  filt:\n",
      " [[[[0 1]\n",
      "   [2 3]]]\n",
      "\n",
      "\n",
      " [[[4 5]\n",
      "   [6 7]]]]\n",
      "  bias:\n",
      " [[0 1]]\n",
      "None\n",
      "z [[[[ -72.  -66.  -60.]\n",
      "   [ -48.  -42.  -36.]\n",
      "   [ -24.  -18.  -12.]]\n",
      "\n",
      "  [[-287. -265. -243.]\n",
      "   [-199. -177. -155.]\n",
      "   [-111.  -89.  -67.]]]\n",
      "\n",
      "\n",
      " [[[  39.   40.   36.]\n",
      "   [  53.   54.   60.]\n",
      "   [  72.   78.   84.]]\n",
      "\n",
      "  [[ 100.  117.  109.]\n",
      "   [ 178.  195.  197.]\n",
      "   [ 241.  263.  285.]]]]\n",
      "f [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 39.  40.  36.]\n",
      "   [ 53.  54.  60.]\n",
      "   [ 72.  78.  84.]]\n",
      "\n",
      "  [[100. 117. 109.]\n",
      "   [178. 195. 197.]\n",
      "   [241. 263. 285.]]]]\n",
      "\n",
      "Pool Information:\n",
      "  tag: pool\n",
      "  pool_i: 2\n",
      "  pool_j: 2\n",
      "  stide_i: 2\n",
      "  stride_j: 2\n",
      "None\n",
      "z [[[[  0.   0.]\n",
      "   [  0.   0.]]\n",
      "\n",
      "  [[  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 54.  60.]\n",
      "   [ 78.  84.]]\n",
      "\n",
      "  [[195. 197.]\n",
      "   [263. 285.]]]]\n",
      "f [[[[  0.   0.]\n",
      "   [  0.   0.]]\n",
      "\n",
      "  [[  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 54.  60.]\n",
      "   [ 78.  84.]]\n",
      "\n",
      "  [[195. 197.]\n",
      "   [263. 285.]]]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 8\n",
      "  neurons_out: 2\n",
      "  weights:\n",
      " [[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]\n",
      " [ 6.  7.]\n",
      " [ 8.  9.]\n",
      " [10. 11.]\n",
      " [12. 13.]\n",
      " [14. 15.]]\n",
      "  bias:\n",
      " [[0. 1.]]\n",
      "None\n",
      "z [[0.0000e+00 1.0000e+00]\n",
      " [1.1612e+04 1.2829e+04]]\n",
      "f [[0.0000e+00 1.0000e+00]\n",
      " [1.1612e+04 1.2829e+04]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 2\n",
      "  neurons_out: 3\n",
      "  weights:\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "  bias:\n",
      " [[0. 1. 2.]]\n",
      "None\n",
      "z [[3.0000e+00 5.0000e+00 7.0000e+00]\n",
      " [3.8487e+04 6.2929e+04 8.7371e+04]]\n",
      "f [[3.0000e+00 5.0000e+00 7.0000e+00]\n",
      " [3.8487e+04 6.2929e+04 8.7371e+04]]\n",
      "\n",
      "y\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "yhat\n",
      " [[ 0.  1. -1.]\n",
      " [ 0.  1. -1.]]\n",
      "y-yhat\n",
      " [[0. 0. 3.]\n",
      " [3. 3. 6.]]\n",
      "\n",
      "dout\n",
      " [[-0. -2.  3.]\n",
      " [-0. -5.  6.]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 2\n",
      "  neurons_out: 3\n",
      "  weights:\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "  bias:\n",
      " [[0. 1. 2.]]\n",
      "dprev\n",
      " [[-0. -2.  3.]\n",
      " [-0. -5.  6.]]\n",
      "f(data)\n",
      " [[0.0000e+00 1.0000e+00]\n",
      " [1.1612e+04 1.2829e+04]]\n",
      "d(data)\n",
      " [[0. 1.]\n",
      " [1. 1.]]\n",
      "weight\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "bias\n",
      " [[0. 1. 2.]]\n",
      "dW\n",
      " [[     0. -58060.  69672.]\n",
      " [     0. -64147.  76977.]]\n",
      "db\n",
      " [[ 0. -7.  9.]]\n",
      "dout\n",
      " [[ 0.  7.]\n",
      " [ 7. 10.]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 8\n",
      "  neurons_out: 2\n",
      "  weights:\n",
      " [[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]\n",
      " [ 6.  7.]\n",
      " [ 8.  9.]\n",
      " [10. 11.]\n",
      " [12. 13.]\n",
      " [14. 15.]]\n",
      "  bias:\n",
      " [[0. 1.]]\n",
      "dprev\n",
      " [[ 0.  7.]\n",
      " [ 7. 10.]]\n",
      "f(data)\n",
      " [[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 54.  60.  78.  84. 195. 197. 263. 285.]]\n",
      "d(data)\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "weight\n",
      " [[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]\n",
      " [ 6.  7.]\n",
      " [ 8.  9.]\n",
      " [10. 11.]\n",
      " [12. 13.]\n",
      " [14. 15.]]\n",
      "bias\n",
      " [[0. 1.]]\n",
      "dW\n",
      " [[ 378.  540.]\n",
      " [ 420.  600.]\n",
      " [ 546.  780.]\n",
      " [ 588.  840.]\n",
      " [1365. 1950.]\n",
      " [1379. 1970.]\n",
      " [1841. 2630.]\n",
      " [1995. 2850.]]\n",
      "db\n",
      " [[ 7. 17.]]\n",
      "dout\n",
      " [[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 10.  44.  78. 112. 146. 180. 214. 248.]]\n",
      "\n",
      "Pool Information:\n",
      "  tag: pool\n",
      "  pool_i: 2\n",
      "  pool_j: 2\n",
      "  stide_i: 2\n",
      "  stride_j: 2\n",
      "dprev\n",
      " [[[[  0.   0.]\n",
      "   [  0.   0.]]\n",
      "\n",
      "  [[  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 10.  44.]\n",
      "   [ 78. 112.]]\n",
      "\n",
      "  [[146. 180.]\n",
      "   [214. 248.]]]]\n",
      "imag_in\n",
      " [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 39.  40.  36.]\n",
      "   [ 53.  54.  60.]\n",
      "   [ 72.  78.  84.]]\n",
      "\n",
      "  [[100. 117. 109.]\n",
      "   [178. 195. 197.]\n",
      "   [241. 263. 285.]]]]\n",
      "dout\n",
      " [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.   0.]\n",
      "   [  0.  10.  44.]\n",
      "   [  0.  78. 112.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0. 146. 180.]\n",
      "   [  0. 214. 248.]]]]\n",
      "\n",
      "Filter Information:\n",
      "  tag: convolution\n",
      "  num_filt: 2\n",
      "  num_ch: 1\n",
      "  f_i: 2\n",
      "  f_j: 2\n",
      "  stride_i: 1\n",
      "  stride_j: 1\n",
      "  filt:\n",
      " [[[[0 1]\n",
      "   [2 3]]]\n",
      "\n",
      "\n",
      " [[[4 5]\n",
      "   [6 7]]]]\n",
      "  bias:\n",
      " [[0 1]]\n",
      "dprev\n",
      " [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.   0.]\n",
      "   [  0.  10.  44.]\n",
      "   [  0.  78. 112.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0. 146. 180.]\n",
      "   [  0. 214. 248.]]]]\n",
      "imag_in\n",
      " [[[[-16. -15. -14. -13.]\n",
      "   [-12. -11. -10.  -9.]\n",
      "   [ -8.  -7.  -6.  -5.]\n",
      "   [ -4.  -3.  -2.  -1.]]]\n",
      "\n",
      "\n",
      " [[[  0.   1.   2.   3.]\n",
      "   [  4.  10.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]]]\n",
      "dfilt\n",
      " [[[[ 2186.  2380.]\n",
      "   [ 3112.  3356.]]]\n",
      "\n",
      "\n",
      " [[[ 6946.  7004.]\n",
      "   [ 9368. 10156.]]]]\n",
      "dbias\n",
      " [[244. 788.]]\n",
      "dout\n",
      " [[[[   0.    0.    0.    0.]\n",
      "   [   0.    0.    0.    0.]\n",
      "   [   0.    0.    0.    0.]\n",
      "   [   0.    0.    0.    0.]]]\n",
      "\n",
      "\n",
      " [[[   0.    0.    0.    0.]\n",
      "   [   0.  584. 1460.  944.]\n",
      "   [   0. 1752. 4360. 2744.]\n",
      "   [   0. 1440. 3444. 2072.]]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filt_info = CInfo([2,-1,2,2])\n",
    "filt = CLayer('convolution',filt_info)\n",
    "\n",
    "pool_info = CInfo([-1,2,2],2,2)\n",
    "pool = CLayer('pool',pool_info)\n",
    "\n",
    "conn_info = CInfo([-1,2])\n",
    "conn = CLayer('connection',conn_info)\n",
    "\n",
    "cnn = CNN([1,4,4],3,[filt,pool,conn],1,1)\n",
    "\n",
    "cnn.layer[0].weight = np.arange(8).reshape(2,1,2,2)\n",
    "cnn.layer[0].bias = np.arange(2).reshape(1,2)\n",
    "cnn.layer[2].weight = np.arange(16).reshape(8,2).astype(float)\n",
    "cnn.layer[2].bias = np.arange(2).reshape(1,2).astype(float)\n",
    "cnn.layer[3].weight = np.arange(6).reshape(2,3).astype(float)\n",
    "cnn.layer[3].bias = np.arange(3).reshape(1,3).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "X = np.arange(-16,16).reshape(2,1,4,4).astype(float)\n",
    "X[1,0,1,1] = 10\n",
    "y = np.arange(6).reshape(2,3).astype(float)\n",
    "yhat = np.zeros(6).reshape(2,3).astype(float)\n",
    "yhat[0][1] = 1\n",
    "yhat[0][2] = -1\n",
    "yhat[1][1] = 1\n",
    "yhat[1][2] = -1\n",
    "\n",
    "print('')\n",
    "print('X\\n',X)\n",
    "print('')\n",
    "print('y\\n',y)\n",
    "print('yhat\\n',yhat)\n",
    "cnn.FFeedForward(X)\n",
    "print('')\n",
    "print('y\\n',y)\n",
    "print('yhat\\n',yhat)\n",
    "print('y-yhat\\n',y-yhat)\n",
    "print('')\n",
    "cnn.FBackPropagation(y,yhat)\n",
    "#cnn.FPrint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\ndef InitializeFilter(dimensions):\\n    return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(dimensions))),size=dimensions)\\n\\n\\ndef Convolution(images, filt, bias, activat, stride_i=1,stride_j=1):\\n    (num_filt, num_ch_f, f_i, f_j) = filt.shape\\n    (num_imag, num_ch, imag_i, imag_j) = images.shape\\n    \\n    if(num_ch_f != num_ch):\\n        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\\n\\n    out_i = int(np.ceil((imag_i - f_i)/stride_i) + 1)\\n    out_j = int(np.ceil((imag_j - f_j)/stride_j) + 1)\\n    z = np.zeros((num_imag, num_filt, out_i, out_j))\\n    i=0\\n    for image in images:\\n        for curr_f in range(num_filt):\\n            curr_y = curr_y_end = out_y = 0\\n            f_y_end = f_j + 1\\n            while(out_y < out_j):\\n                curr_x = curr_x_end = out_x = 0\\n                curr_y_end = curr_y + f_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                    f_y_end = curr_y_end - curr_y\\n                f_x_end = f_i + 1\\n                while(out_x < out_i):\\n                    curr_x_end = curr_x + f_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                        f_x_end = curr_x_end - curr_x\\n                    z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + bias[curr_f]\\n                    curr_x += stride_i\\n                    out_x += 1\\n                curr_y += stride_j\\n                out_y += 1\\n        i+=1\\n    return z,activat(z)\\n\\ndef FMaxPool(images,pool_i=2,pool_j=2,stride_i=2,stride_j=2):\\n    (num_imag, num_ch, imag_i, imag_j) = images.shape\\n\\n    out_i = int(np.ceil((imag_i - pool_i)/stride_i)) + 1\\n    out_j = int(np.ceil((imag_j - pool_j)/stride_j)) + 1\\n    z = np.zeros((num_imag, num_ch, out_i, out_j))\\n    index = np.zeros((num_imag, num_ch, out_i, out_j))\\n    \\n    i=0\\n    for image in images:\\n        for curr_chan in range(num_ch):\\n            curr_y = out_y = 0\\n            while(out_y < out_j):\\n                curr_x = out_x = 0\\n                curr_y_end = curr_y + pool_j\\n                if(curr_y_end > imag_j):\\n                    current_y_end = imag_j\\n                while(out_x < out_i):\\n                    curr_x_end = curr_x + pool_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                    z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\\n                    index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\\n                    curr_x += stride_i\\n                    out_x +=1\\n                curr_y += stride_j\\n                out_y += 1\\n        i+=1\\n    return z,index\\n\\ndef FConnection(images,weights,bias,activation):\\n    z = images.dot(weights) + bias\\n    return z, activation(z)\\n\\ndef FbackConvolution(dprev,conv_in,filt,derivative,stride_i=1,stride_j=1):\\n    (num_filt, num_ch_f, f_i, f_j) = filt.shape\\n    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\\n    \\n    if(num_ch_f != num_ch):\\n        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\\n\\n    dout = np.zeros((num_ch,imag_i,imag_j))\\n    dfilt = np.zeros(filt.shape)\\n    dbias = np.zeros((num_filt,1))\\n    \\n    for conv in conv_in:\\n        dout_conv = np.zeros((num_ch,imag_i,imag_j))\\n        for curr_f in range(num_filt):\\n            curr_y = out_y = 0\\n            f_y_end = f_i\\n            while(curr_y + f_j < imag_j + 1):\\n                curr_x = out_x = 0\\n                curr_y_end = curr_y + f_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                    f_y_end = curr_y_end - curr_y\\n                f_x_end = f_j\\n                while(curr_x + f_i < imag_i + 1): \\n                    curr_x_end = curr_x + f_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                        f_x_end = curr_x_end - curr_i\\n                    dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\\n                    dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\\n\\n                    curr_x += stride_i\\n                    out_x +=1\\n                curr_y += stride_j\\n                out_y += 1\\n            dbias[curr_f] = np.sum(dprev[curr_f])\\n        dout += dout_conv*derivative(conv)\\n\\n    return dout,dfilt,dbias\\n\\ndef FbackMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2):\\n    (num_ch_p, dp_i, dp_j) = dpool.shape\\n    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\\n    \\n    if(num_ch_p != num_ch):\\n        print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\\n\\n    dout = np.zeros((num_ch,imag_i,imag_j))\\n    \\n    for conv in conv_in:\\n        for curr_ch in range(num_ch):\\n            curr_y = curr_y_end = out_y = 0\\n            while(out_y < dp_j):\\n                curr_x = curr_x_end = out_x = 0\\n                curr_y_end = curr_y + p_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                while(out_x < dp_i):\\n                    curr_x_end = curr_x + p_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                    (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\\n                    dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\\n\\n                    curr_x += stride_i\\n                    out_x += 1\\n                curr_y += stride_j\\n                out_y += 1\\n    return dout\\n\\ndef FbackConnection(dprev,data_in,weight,activation,derivative):\\n    dW = activation(data_in).T.dot(dprev)\\n    db = np.sum(dprev,axis=0,keepdims=True)\\n    dout = dprev.dot(weight.T)*derivative(data_in)\\n    return dout, dW, db\\n    \\n#def Convolution(images, filt, bias, activation, stride_i=1,stride_j=1):\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "def InitializeFilter(dimensions):\n",
    "    return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(dimensions))),size=dimensions)\n",
    "\n",
    "\n",
    "def Convolution(images, filt, bias, activat, stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - f_i)/stride_i) + 1)\n",
    "    out_j = int(np.ceil((imag_j - f_j)/stride_j) + 1)\n",
    "    z = np.zeros((num_imag, num_filt, out_i, out_j))\n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            f_y_end = f_j + 1\n",
    "            while(out_y < out_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_i + 1\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_x\n",
    "                    z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + bias[curr_f]\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,activat(z)\n",
    "\n",
    "def FMaxPool(images,pool_i=2,pool_j=2,stride_i=2,stride_j=2):\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - pool_i)/stride_i)) + 1\n",
    "    out_j = int(np.ceil((imag_j - pool_j)/stride_j)) + 1\n",
    "    z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    index = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    \n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_chan in range(num_ch):\n",
    "            curr_y = out_y = 0\n",
    "            while(out_y < out_j):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + pool_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    current_y_end = imag_j\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + pool_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,index\n",
    "\n",
    "def FConnection(images,weights,bias,activation):\n",
    "    z = images.dot(weights) + bias\n",
    "    return z, activation(z)\n",
    "\n",
    "def FbackConvolution(dprev,conv_in,filt,derivative,stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dbias = np.zeros((num_filt,1))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        dout_conv = np.zeros((num_ch,imag_i,imag_j))\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = out_y = 0\n",
    "            f_y_end = f_i\n",
    "            while(curr_y + f_j < imag_j + 1):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_j\n",
    "                while(curr_x + f_i < imag_i + 1): \n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_i\n",
    "                    dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\n",
    "                    dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "            dbias[curr_f] = np.sum(dprev[curr_f])\n",
    "        dout += dout_conv*derivative(conv)\n",
    "\n",
    "    return dout,dfilt,dbias\n",
    "\n",
    "def FbackMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2):\n",
    "    (num_ch_p, dp_i, dp_j) = dpool.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_p != num_ch):\n",
    "        print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        for curr_ch in range(num_ch):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            while(out_y < dp_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + p_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                while(out_x < dp_i):\n",
    "                    curr_x_end = curr_x + p_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                    dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "    return dout\n",
    "\n",
    "def FbackConnection(dprev,data_in,weight,activation,derivative):\n",
    "    dW = activation(data_in).T.dot(dprev)\n",
    "    db = np.sum(dprev,axis=0,keepdims=True)\n",
    "    dout = dprev.dot(weight.T)*derivative(data_in)\n",
    "    return dout, dW, db\n",
    "    \n",
    "#def Convolution(images, filt, bias, activation, stride_i=1,stride_j=1):\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
