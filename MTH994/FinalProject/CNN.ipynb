{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Here I've coded an artificial neural network with an arbitrary number of layers. The ANN is encoded in a class, and is fed a dictionary of your choices for activation functions and loss functions, as well as a list of the neurons in each layer, for example a two layer network with 100 and 50, respectively, is fed as [100,50].\n",
    "\n",
    "Then, the easiest way to search for effective parameters sets is to use RunOne or RunTwo. RunOne will train a one layer NN across the list of options you feed it, then test its accuracy. For example, [10,20,30] will train with 10 neurons, 20 neurons, 30 neurons, and spit out the accuracy for each. Similarly, RunTwo trains in a list of two lists, the first for the number of neurons in the first layer and the second for the second layer. It will train across all combinations and sit out a matrix of accuracies.\n",
    "\n",
    "Then, once you've identified a good parameter set, use the solitary Train function grouped with RunOne and RunTwo in order to train one a specific parameter set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def read_dataset(feature_file, label_file):\n",
    "    ''' Read data set in *.csv to data frame in Pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (features)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def normalize_features(X_train, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler #import libaray\n",
    "    scaler = StandardScaler() # call an object function\n",
    "    scaler.fit(X_train) # calculate mean, std in X_train\n",
    "    X_train_norm = scaler.transform(X_train) # apply normalization on X_train\n",
    "    X_test_norm = scaler.transform(X_test) # we use the same normalization on X_test\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "\n",
    "def one_hot_encoder(y_train, y_test):\n",
    "    ''' convert label to a vector under one-hot-code fashion '''\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    y_train_ohe = lb.transform(y_train)\n",
    "    y_test_ohe = lb.transform(y_test)\n",
    "    return y_train_ohe, y_test_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "X_train_digits, y_train_digits = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test_digits, y_test_digits = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "X_train_norm_digits, X_test_norm_digits = normalize_features(X_train_digits, X_test_digits)\n",
    "y_train_ohe_digits, y_test_ohe_digits = one_hot_encoder(y_train_digits, y_test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW IS TESTING! DIVE IN; THE WATER'S FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFilter:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"convolution\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_filt = info.dimensions[0]\n",
    "        self.num_ch = info.dimensions[1]\n",
    "        self.f_i = info.dimensions[2]\n",
    "        self.f_j = info.dimensions[3]\n",
    "        self.weight = self.FInitializeFilter()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j\n",
    "        self.activation = info.activation        \n",
    "    def FInitializeFilter(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.dimensions))),size=self.dimensions)\n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.num_filt))),size=(1,self.num_filt))\n",
    "    \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.f_i)/self.stride_i) + 1)\n",
    "        out_j = int(np.ceil((imag_j - self.f_j)/self.stride_j) + 1)\n",
    "        z = np.zeros((num_imag, self.num_filt, out_i, out_j))\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                f_y_end = self.f_j\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y\n",
    "                    f_x_end = self.f_i\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x\n",
    "                        z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*self.weight[curr_f,:,0:f_x_end,0:f_y_end]) + self.bias[0][curr_f]\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,imag_in):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag,num_ch,imag_i,imag_j))\n",
    "        dfilt = np.zeros(self.weight.shape)\n",
    "        dbias = np.zeros((1,self.num_filt))\n",
    "\n",
    "        for i in range(imag_in.shape[0]):\n",
    "            for curr_f in range(self.num_filt):\n",
    "                curr_y = out_y = 0\n",
    "                f_y_end = self.f_i\n",
    "                while(curr_y + self.f_j < imag_j + 1):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.f_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                        f_y_end = curr_y_end - curr_y + 1\n",
    "                    f_x_end = self.f_j\n",
    "                    while(curr_x + self.f_i < imag_i + 1): \n",
    "                        curr_x_end = curr_x + self.f_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                            f_x_end = curr_x_end - curr_x + 1                      \n",
    "                        dout[i,:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[i,curr_f, out_x, out_y] * self.weight[curr_f,:,:f_x_end,:f_y_end]\n",
    "                        dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[i,curr_f,out_x,out_y] * imag_in[i,:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "                dbias[0][curr_f] += np.sum(dprev[i,curr_f])\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('imag_in\\n',imag_in) \n",
    "        print('dfilt\\n',dfilt)\n",
    "        print('dbias\\n',dbias)\n",
    "        '''\n",
    "        return dout,dfilt,dbias\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Filter Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  num_filt:\",self.num_filt)\n",
    "        print(\"  num_ch:\",self.num_ch)\n",
    "        print(\"  f_i:\",self.f_i)\n",
    "        print(\"  f_j:\",self.f_j)\n",
    "        print(\"  stride_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "        #print(\"  act.f:\",self.activation.f)\n",
    "        #print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  filt:\\n\",self.weight)\n",
    "        print(\"  bias:\\n\",self.bias)\n",
    "\n",
    "class CPool:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"pool\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.num_ch = info.dimensions[0]\n",
    "        self.pool_i = info.dimensions[1]\n",
    "        self.pool_j = info.dimensions[2]\n",
    "        self.stride_i = info.stride_i\n",
    "        self.stride_j = info.stride_j  \n",
    "        \n",
    "    def FFeedForward(self,images):\n",
    "        (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "        if(self.num_ch != num_ch):\n",
    "            print(\"Big mistake! The number of channels in the pool does not match the number of channels in the input!\")\n",
    "\n",
    "        out_i = int(np.ceil((imag_i - self.pool_i)/self.stride_i)) + 1\n",
    "        out_j = int(np.ceil((imag_j - self.pool_j)/self.stride_j)) + 1\n",
    "        z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "\n",
    "        i=0\n",
    "        for image in images:\n",
    "            for curr_chan in range(self.num_ch):\n",
    "                curr_y = out_y = 0\n",
    "                while(out_y < out_j):\n",
    "                    curr_x = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        current_y_end = imag_j\n",
    "                    while(out_x < out_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan, curr_x:curr_x_end, curr_y:curr_y_end])\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x +=1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "            i+=1\n",
    "        return z,z\n",
    "\n",
    "    def FFeedBack(self, dprev, imag_in):\n",
    "        (num_imag_p, num_ch_p, dp_i, dp_j) = dprev.shape\n",
    "        (num_imag, num_ch, imag_i, imag_j) = imag_in.shape\n",
    "\n",
    "        if(num_ch_p != num_ch):\n",
    "            print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "        dout = np.zeros((num_imag, num_ch,imag_i,imag_j))\n",
    "        for i in range(imag_in.shape[0]):\n",
    "            for curr_ch in range(num_ch):\n",
    "                curr_y = curr_y_end = out_y = 0\n",
    "                while(out_y < dp_j):\n",
    "                    curr_x = curr_x_end = out_x = 0\n",
    "                    curr_y_end = curr_y + self.pool_j\n",
    "                    if(curr_y_end > imag_j):\n",
    "                        curr_y_end = imag_j\n",
    "                    while(out_x < dp_i):\n",
    "                        curr_x_end = curr_x + self.pool_i\n",
    "                        if(curr_x_end > imag_i):\n",
    "                            curr_x_end = imag_i\n",
    "                        (a,b) = np.unravel_index(np.nanargmax(imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),imag_in[i,curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                        dout[i,curr_ch,curr_x+a,curr_y+b] += dprev[i,curr_ch,out_x,out_y]\n",
    "\n",
    "                        curr_x += self.stride_i\n",
    "                        out_x += 1\n",
    "                    curr_y += self.stride_j\n",
    "                    out_y += 1\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('imag_in\\n',imag_in)\n",
    "        '''\n",
    "        return dout\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Pool Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  pool_i:\",self.pool_i)\n",
    "        print(\"  pool_j:\",self.pool_j)\n",
    "        print(\"  stide_i:\",self.stride_i)\n",
    "        print(\"  stride_j:\",self.stride_j)\n",
    "\n",
    "class CConnection:\n",
    "    def __init__(self,info):\n",
    "        self.tag = \"connection\"\n",
    "        self.dimensions = info.dimensions\n",
    "        self.neurons_in = info.dimensions[0]\n",
    "        self.neurons_out = info.dimensions[1]\n",
    "        self.weight = self.FInitializeWeights()\n",
    "        self.bias = self.FInitializeBias()\n",
    "        self.activation = info.activation\n",
    "   \n",
    "    def FInitializeWeights(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod([self.neurons_in,self.neurons_out]))),size=[self.neurons_in,self.neurons_out])\n",
    "       \n",
    "    def FInitializeBias(self):\n",
    "        return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(self.neurons_out))),size=(1,self.neurons_out))\n",
    "\n",
    "    def FFeedForward(self,images):\n",
    "        z = images.dot(self.weight) + self.bias\n",
    "        return z, self.activation.f(z)\n",
    "    \n",
    "    def FFeedBack(self,dprev,data_in):\n",
    "        dW = self.activation.f(data_in).T.dot(dprev)\n",
    "        db = np.sum(dprev,axis=0,keepdims=True)\n",
    "        dout = dprev.dot(self.weight.T)*self.activation.d(data_in)\n",
    "        '''\n",
    "        print('')\n",
    "        self.FPrint()\n",
    "        print('dprev\\n',dprev)\n",
    "        print('f(data)\\n',self.activation.f(data_in))\n",
    "        print('d(data)\\n',self.activation.d(data_in))\n",
    "        print('weight\\n',self.weight)\n",
    "        print('bias\\n',self.bias)\n",
    "        print('dW\\n',dW)\n",
    "        print('db\\n',db)\n",
    "        '''\n",
    "        return dout, dW, db\n",
    "\n",
    "    def FPrint(self):\n",
    "        print(\"Connection Information:\")\n",
    "        print(\"  tag:\",self.tag)\n",
    "        print(\"  neurons_in:\",self.neurons_in)\n",
    "        print(\"  neurons_out:\",self.neurons_out)\n",
    "        #print(\"  act.f:\",self.activation.f)\n",
    "        #print(\"  act.d:\",self.activation.d)\n",
    "        print(\"  weights:\\n\",self.weight)\n",
    "        print(\"  bias:\\n\",self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLinear(X):\n",
    "    return X\n",
    "def FRELU(X):\n",
    "    a = np.copy(X)\n",
    "    a[X<0]=0\n",
    "    return a\n",
    "def FRELU_dx(X):\n",
    "    dx = np.zeros(X.shape)\n",
    "    dx[X>0] = 1\n",
    "    return dx\n",
    "\n",
    "def RegularizedLoss(y,yhat,regularization_parameter,C):\n",
    "    loss = 0\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    hinge[hinge<0]=0\n",
    "    loss = np.sum(hinge)\n",
    "    loss *= regularization_parameter\n",
    "    temp = 0\n",
    "    for item in C:\n",
    "        for elem in item:\n",
    "            temp += np.sum(elem*elem)\n",
    "    return loss + np.sqrt(temp)\n",
    "\n",
    "def RegularizedLoss_dx(y,yhat,regularization_parameter):\n",
    "    hinge = 1 - y*yhat\n",
    "    hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "    summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "    loss = np.zeros(y.shape)\n",
    "    for i in range(hinge.shape[0]):\n",
    "        if(hinge[i]>0):\n",
    "            loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "    loss *= regularization_parameter\n",
    "    return loss\n",
    "\n",
    "def softmax(z):\n",
    "    exp_value = np.exp(z-np.amax(z, axis=1, keepdims=True)) # for stablility\n",
    "    # keepdims = True means that the output's dimension is the same as of z\n",
    "    softmax_scores = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
    "    return softmax_scores\n",
    "def accuracy(ypred, yexact):\n",
    "    p = np.array(ypred == yexact, dtype = int)\n",
    "    return np.sum(p)/float(len(yexact))\n",
    "\n",
    "class CActivation:\n",
    "    def __init__(self,Function,Derivative):\n",
    "        self.f = Function\n",
    "        self.d = Derivative\n",
    "\n",
    "RELU  = CActivation(FRELU,FRELU_dx)\n",
    "class CLayer:\n",
    "    def __init__(self,Tag,Info):\n",
    "        self.tag = Tag\n",
    "        self.info = Info\n",
    "        self.indim = None\n",
    "        self.outdim = None\n",
    "        \n",
    "class CInfo:\n",
    "    def __init__(self,dimensions=None,stride_i=1,stride_j=1,activation=RELU):\n",
    "        self.dimensions = dimensions\n",
    "        self.stride_i = stride_i\n",
    "        self.stride_j = stride_j\n",
    "        self.activation = activation\n",
    "    def FAddDimensions(self,Dimensions):\n",
    "        self.dimensions = Dimensions\n",
    "    def FAddStride(self,Stride_i=1,Stride_j=1):\n",
    "        self.stride_i = Stride_i\n",
    "        self.stride_j = Stride_j\n",
    "    def FAddActivation(self,Activation):\n",
    "        self.activation = Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, indim, outdim, LayersInfo, lr=0.1, rp=0.1):\n",
    "        self.in_ch = []\n",
    "        self.indim_i = []\n",
    "        self.indim_j = []\n",
    "        self.in_ch.append(indim[0])\n",
    "        self.indim_i.append(indim[1])\n",
    "        self.indim_j.append(indim[1])\n",
    "        self.outdim = outdim\n",
    "\n",
    "        #self.X = X\n",
    "        #self.X_reshape = self.X.reshape(self.samples,self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        #self.y = y\n",
    "        self.lr = lr\n",
    "        self.rp = rp\n",
    "        self.probability = softmax\n",
    "\n",
    "        self.layer = []\n",
    "        for Layer in LayersInfo:\n",
    "            self.layer.append(self.FAddLayer(Layer))\n",
    "        outinfo = CInfo([-1,self.outdim])\n",
    "        finallayer = CLayer('connection',outinfo)\n",
    "        self.layer.append(self.FAddLayer(finallayer))\n",
    "            \n",
    "\n",
    "    def FAddLayer(self,Layer):\n",
    "        if(Layer.tag=='convolution'):\n",
    "            Layer.info.dimensions[1] = self.in_ch[-1]\n",
    "            self.in_ch.append(Layer.info.dimensions[0])\n",
    "            f_i = Layer.info.dimensions[2]\n",
    "            f_j = Layer.info.dimensions[3]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.indim_i.append(int(np.ceil((indim_i - f_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - f_j)/stride_j) + 1))\n",
    "            return CFilter(Layer.info)\n",
    "        elif(Layer.tag=='pool'):\n",
    "            Layer.info.dimensions[0] = self.in_ch[-1]\n",
    "            p_i = Layer.info.dimensions[1]\n",
    "            p_j = Layer.info.dimensions[2]\n",
    "            stride_i = Layer.info.stride_i\n",
    "            stride_j = Layer.info.stride_j\n",
    "            indim_i = self.indim_i[-1]\n",
    "            indim_j = self.indim_j[-1]\n",
    "            self.in_ch.append(self.in_ch[-1])\n",
    "            self.indim_i.append(int(np.ceil((indim_i - p_i)/stride_i) + 1))\n",
    "            self.indim_j.append(int(np.ceil((indim_j - p_j)/stride_j) + 1))\n",
    "            return CPool(Layer.info)\n",
    "        elif(Layer.tag=='connection'):\n",
    "            flatten = self.in_ch[-1]*self.indim_i[-1]*self.indim_j[-1]\n",
    "            Layer.info.dimensions[0] = flatten\n",
    "            self.in_ch.append(1)\n",
    "            self.indim_i.append(1)\n",
    "            self.indim_j.append(Layer.info.dimensions[1])\n",
    "            return CConnection(Layer.info)\n",
    "        else:\n",
    "            print(Layer.tag,'is not a valid layer option. Double check initialization.')\n",
    "            return None\n",
    "\n",
    "    def FPrint(self):\n",
    "        for l in self.layer:\n",
    "            l.FPrint()\n",
    "\n",
    "    def FFeedForward(self,X):\n",
    "        self.z = []\n",
    "        self.f = []\n",
    "        images = X.reshape(X.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        self.f.append(images)\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            self.z.append(Z)\n",
    "            if(i != len(self.layer) -1):\n",
    "                self.f.append(F)\n",
    "            images = self.f[-1]\n",
    "            '''\n",
    "            print('')\n",
    "            print(self.layer[i].FPrint())\n",
    "            print('z',Z)\n",
    "            print('f',F)\n",
    "            '''\n",
    "        self.yhat = self.probability(self.z[-1])\n",
    "        \n",
    "    def FBackPropagation(self,y):\n",
    "        d = []\n",
    "        d.insert(0,self.Loss_dx(y,self.yhat)) \n",
    "        #print('dout\\n',d[0])\n",
    "        for i in range(len(self.layer)):\n",
    "            images = self.f[-1-i]\n",
    "            if(self.layer[-1-i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            elif(self.layer[-1-i+1].tag == 'connection'):\n",
    "                d[0] = np.reshape(d[0],(images.shape[0],self.in_ch[-1-i],self.indim_i[-1-i],self.indim_j[-1-i]))\n",
    "            if(self.layer[-1-i].tag != 'pool'):\n",
    "                dout,dW,db = self.layer[-1-i].FFeedBack(d[0],images)\n",
    "                #dW /= float(len(y))\n",
    "                #db /= float(len(y))\n",
    "                self.layer[-1-i].weight = self.layer[-1-i].weight - self.lr*dW\n",
    "                if(self.rp != 0 and self.layer[-1-i].weight.all() !=0 ):\n",
    "                    self.layer[-1-i].weight = self.layer[-1-i].weight - self.rp*self.layer[-1-i].weight/np.sqrt(np.sum(self.layer[-1-i].weight*self.layer[-1-i].weight))/self.layer[-1-i].weight.size\n",
    "\n",
    "                self.layer[-1-i].bias = self.layer[-1-i].bias - self.lr*db\n",
    "                if(self.rp != 0 and self.layer[-1-i].bias.all() !=0 ):\n",
    "                    self.layer[-1-i].bias = self.layer[-1-i].bias - self.rp*self.layer[-1-i].bias/np.sqrt(np.sum(self.layer[-1-i].bias*self.layer[-1-i].bias))/self.layer[-1-i].bias.size  \n",
    "            else:\n",
    "                dout = self.layer[-1-i].FFeedBack(d[0],self.f[-1-i])\n",
    "                \n",
    "            d.insert(0,dout)\n",
    "            #print('dout\\n',d[0])\n",
    "            \n",
    "    def Loss(self,y,yhat):\n",
    "        loss = 0\n",
    "        hinge = 1 - y*yhat\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        hinge[hinge<0]=0\n",
    "        loss = np.sum(hinge)\n",
    "        loss *= self.rp\n",
    "        temp = 0\n",
    "        for l in self.layer:\n",
    "            if(l.tag != 'pool'):\n",
    "                temp += np.sum(l.weight*l.weight)\n",
    "                temp += np.sum(l.bias*l.bias)\n",
    "        return loss + np.sqrt(temp)\n",
    "\n",
    "    def Loss_dx(self,y,yhat):\n",
    "        hinge = 1 - y*yhat\n",
    "        #print('hinge\\n',hinge)\n",
    "        hinge = np.sum(hinge,axis=1,keepdims=True)\n",
    "        #print('hinge\\n',hinge)\n",
    "        summed = np.sum(y*yhat,axis=1,keepdims=True)\n",
    "        #print('summed\\n',summed)\n",
    "        loss = np.zeros(y.shape)\n",
    "        for i in range(hinge.shape[0]):\n",
    "            if(hinge[i]>0):\n",
    "                loss[i] = yhat[i]*(summed[i] - y[i])\n",
    "        #print('dloss\\n',loss)\n",
    "        loss *= self.rp\n",
    "        #print('dloss\\n',loss)\n",
    "        return loss   \n",
    "    \n",
    "    def FPredict(self, X_test):\n",
    "        images = X_test.reshape(X_test.shape[0],self.in_ch[0],self.indim_i[0],self.indim_j[0])\n",
    "        f = images\n",
    "        for i in range(0,len(self.layer)):\n",
    "            if(self.layer[i].tag == 'connection'):\n",
    "                images = np.reshape(images,(images.shape[0],-1))\n",
    "            Z,F = self.layer[i].FFeedForward(images)\n",
    "            images = F\n",
    "        yhat = self.probability(Z)\n",
    "       \n",
    "        # the rest is similar to the logistic regression\n",
    "        labels = np.arange(0,self.outdim+1)\n",
    "        num_test_samples = X_test.shape[0]\n",
    "        # find which index gives us the highest probability\n",
    "        ypred = np.zeros(num_test_samples, dtype=int)\n",
    "        for i in range(num_test_samples):\n",
    "            ypred[i] = labels[np.argmax(yhat[i,:])]\n",
    "        return ypred\n",
    "\n",
    "    def FTrain(self,epochs,batchsize,X,y,Xtest,ytest):\n",
    "        batches = int(np.ceil(X.shape[0]/batchsize))\n",
    "        for i in range(epochs):\n",
    "            for j in range(batches):\n",
    "                start = j*batchsize\n",
    "                end = start + batchsize\n",
    "                if(end > X_train_norm.shape[0]):\n",
    "                    end = X_train_norm.shape[0]\n",
    "                X_ = X[start:end]\n",
    "                y_ = y[start:end]\n",
    "                cnn.FFeedForward(X_)\n",
    "                cnn.FBackPropagation(y_)\n",
    "                #if((i+1)%(epochs/10) == 0):\n",
    "                ypred = cnn.FPredict(Xtest)\n",
    "                print(i+1,j,accuracy(ypred.ravel(),ytest.ravel()),'\\n  Loss: ',self.Loss(y_,self.yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 0.18444444444444444 \n",
      "Loss:  135.96337930365544\n",
      "1 1 0.13333333333333333 \n",
      "Loss:  135.97232038783682\n",
      "1 2 0.13777777777777778 \n",
      "Loss:  135.99128822512927\n",
      "1 3 0.19555555555555557 \n",
      "Loss:  135.94999337664555\n",
      "1 4 0.2088888888888889 \n",
      "Loss:  135.9588073844459\n",
      "1 5 0.1711111111111111 \n",
      "Loss:  135.9545311382693\n",
      "1 6 0.20666666666666667 \n",
      "Loss:  135.9509844867974\n",
      "1 7 0.2111111111111111 \n",
      "Loss:  135.92385824435794\n",
      "1 8 0.21333333333333335 \n",
      "Loss:  135.94726506776976\n",
      "1 9 0.21333333333333335 \n",
      "Loss:  132.92502003807977\n",
      "2 0 0.21333333333333335 \n",
      "Loss:  135.8795078043894\n",
      "2 1 0.20666666666666667 \n",
      "Loss:  135.88617893159076\n",
      "2 2 0.20666666666666667 \n",
      "Loss:  135.89992800292026\n",
      "2 3 0.21333333333333335 \n",
      "Loss:  135.86972002237476\n",
      "2 4 0.21555555555555556 \n",
      "Loss:  135.87663739575225\n",
      "2 5 0.21333333333333335 \n",
      "Loss:  135.8735806296076\n",
      "2 6 0.21333333333333335 \n",
      "Loss:  135.87205230339515\n",
      "2 7 0.21555555555555556 \n",
      "Loss:  135.85205233783543\n",
      "2 8 0.21555555555555556 \n",
      "Loss:  135.86757243491033\n",
      "2 9 0.21333333333333335 \n",
      "Loss:  132.8595898758506\n",
      "3 0 0.21555555555555556 \n",
      "Loss:  135.81744449568907\n",
      "3 1 0.21555555555555556 \n",
      "Loss:  135.821437575694\n",
      "3 2 0.21555555555555556 \n",
      "Loss:  135.8284929558423\n",
      "3 3 0.21555555555555556 \n",
      "Loss:  135.8103219263056\n",
      "3 4 0.21555555555555556 \n",
      "Loss:  135.81519406835145\n",
      "3 5 0.21333333333333335 \n",
      "Loss:  135.8129541654748\n",
      "3 6 0.21777777777777776 \n",
      "Loss:  135.81396378332656\n",
      "3 7 0.21777777777777776 \n",
      "Loss:  135.8021295963491\n",
      "3 8 0.21777777777777776 \n",
      "Loss:  135.8093304199572\n",
      "3 9 0.21777777777777776 \n",
      "Loss:  132.8139115073819\n",
      "4 0 0.21777777777777776 \n",
      "Loss:  135.77634933867708\n",
      "4 1 0.21777777777777776 \n",
      "Loss:  135.77735437398144\n",
      "4 2 0.22 \n",
      "Loss:  135.77713221645607\n",
      "4 3 0.23333333333333334 \n",
      "Loss:  135.77205014162112\n",
      "4 4 0.26 \n",
      "Loss:  135.77594231394716\n",
      "4 5 0.34 \n",
      "Loss:  135.7737675107657\n",
      "4 6 0.38 \n",
      "Loss:  135.77713049732859\n",
      "4 7 0.3888888888888889 \n",
      "Loss:  135.7761312086825\n",
      "4 8 0.4177777777777778 \n",
      "Loss:  135.77302347802404\n",
      "4 9 0.4088888888888889 \n",
      "Loss:  132.79012326042744\n",
      "5 0 0.4088888888888889 \n",
      "Loss:  135.75845758185702\n",
      "5 1 0.4111111111111111 \n",
      "Loss:  135.7555886748957\n",
      "5 2 0.4222222222222222 \n",
      "Loss:  135.745981686556\n",
      "5 3 0.42 \n",
      "Loss:  135.75616501226335\n",
      "5 4 0.44 \n",
      "Loss:  135.76099780351132\n",
      "5 5 0.4533333333333333 \n",
      "Loss:  135.7576810416813\n",
      "5 6 0.4533333333333333 \n",
      "Loss:  135.76148640090454\n",
      "5 7 0.4533333333333333 \n",
      "Loss:  135.77664184939024\n",
      "5 8 0.4533333333333333 \n",
      "Loss:  135.7579598113706\n",
      "5 9 0.4622222222222222 \n",
      "Loss:  132.78785827148542\n",
      "6 0 0.4533333333333333 \n",
      "Loss:  135.76448955340686\n",
      "6 1 0.44666666666666666 \n",
      "Loss:  135.755955038299\n",
      "6 2 0.42444444444444446 \n",
      "Loss:  135.73157079094398\n",
      "6 3 0.43777777777777777 \n",
      "Loss:  135.76085931085984\n",
      "6 4 0.4622222222222222 \n",
      "Loss:  135.77031189284318\n",
      "6 5 0.4688888888888889 \n",
      "Loss:  135.76340250879767\n",
      "6 6 0.4488888888888889 \n",
      "Loss:  135.76317896086096\n",
      "6 7 0.46 \n",
      "Loss:  135.80475746416138\n",
      "6 8 0.44666666666666666 \n",
      "Loss:  135.76017156625522\n",
      "6 9 0.43777777777777777 \n",
      "Loss:  132.79912481336365\n",
      "7 0 0.44222222222222224 \n",
      "Loss:  135.78491186376544\n",
      "7 1 0.43777777777777777 \n",
      "Loss:  135.7687802048927\n",
      "7 2 0.3888888888888889 \n",
      "Loss:  135.71451739770868\n",
      "7 3 0.39111111111111113 \n",
      "Loss:  135.7644022133293\n",
      "7 4 0.4177777777777778 \n",
      "Loss:  135.79094179315706\n",
      "7 5 0.42444444444444446 \n",
      "Loss:  135.7714817062269\n",
      "7 6 0.3844444444444444 \n",
      "Loss:  135.74050749476467\n",
      "7 7 0.38222222222222224 \n",
      "Loss:  135.85811862909097\n",
      "7 8 0.34 \n",
      "Loss:  135.7209324490784\n",
      "7 9 0.32222222222222224 \n",
      "Loss:  132.7674528282887\n",
      "8 0 0.3111111111111111 \n",
      "Loss:  135.7773102602474\n",
      "8 1 0.30666666666666664 \n",
      "Loss:  135.71436999759356\n",
      "8 2 0.24444444444444444 \n",
      "Loss:  135.50119772987136\n",
      "8 3 0.24444444444444444 \n",
      "Loss:  135.59206683652118\n",
      "8 4 0.2688888888888889 \n",
      "Loss:  135.70444781180757\n",
      "8 5 0.29333333333333333 \n",
      "Loss:  135.55622054847046\n",
      "8 6 0.2733333333333333 \n",
      "Loss:  135.32674735051057\n",
      "8 7 0.29777777777777775 \n",
      "Loss:  135.78740781418577\n",
      "8 8 0.28444444444444444 \n",
      "Loss:  135.17148185234294\n",
      "8 9 0.2911111111111111 \n",
      "Loss:  132.26590523237988\n",
      "9 0 0.29555555555555557 \n",
      "Loss:  135.23421945294143\n",
      "9 1 0.33555555555555555 \n",
      "Loss:  135.05863073501604\n",
      "9 2 0.3377777777777778 \n",
      "Loss:  134.37239033122205\n",
      "9 3 0.39555555555555555 \n",
      "Loss:  134.72390680675636\n",
      "9 4 0.36666666666666664 \n",
      "Loss:  134.89423664883947\n",
      "9 5 0.41333333333333333 \n",
      "Loss:  134.47109576048445\n",
      "9 6 0.38222222222222224 \n",
      "Loss:  134.2396673379927\n",
      "9 7 0.3933333333333333 \n",
      "Loss:  134.97073841078506\n",
      "9 8 0.3844444444444444 \n",
      "Loss:  133.94929813741308\n",
      "9 9 0.5622222222222222 \n",
      "Loss:  131.2927934605229\n",
      "10 0 0.56 \n",
      "Loss:  133.7105986003025\n",
      "10 1 0.6 \n",
      "Loss:  133.6517934646397\n",
      "10 2 0.5711111111111111 \n",
      "Loss:  132.50478967356338\n",
      "10 3 0.5666666666666667 \n",
      "Loss:  132.74186930794733\n",
      "10 4 0.5911111111111111 \n",
      "Loss:  132.84954433502494\n",
      "10 5 0.5466666666666666 \n",
      "Loss:  132.27527909246163\n",
      "10 6 0.5977777777777777 \n",
      "Loss:  133.24627681671606\n",
      "10 7 0.6177777777777778 \n",
      "Loss:  133.26988901378016\n",
      "10 8 0.5977777777777777 \n",
      "Loss:  132.45859881586105\n",
      "10 9 0.6111111111111112 \n",
      "Loss:  129.21359740801037\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test, y_test = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "X_train_norm, X_test_norm = normalize_features(X_train_digits, X_test_digits)\n",
    "y_train_ohe, y_test_ohe = one_hot_encoder(y_train_digits, y_test_digits)\n",
    "\n",
    "\n",
    "filt_info = CInfo([8,-1,3,3])\n",
    "filt = CLayer('convolution',filt_info)\n",
    "\n",
    "pool_info = CInfo([-1,2,2],2,2)\n",
    "pool = CLayer('pool',pool_info)\n",
    "\n",
    "conn_info = CInfo([-1,100])\n",
    "conn = CLayer('connection',conn_info)\n",
    "\n",
    "cnn = CNN([1,8,8],10,[filt,pool,conn],0.05,0.1)\n",
    "epochs = 10\n",
    "batches = 10\n",
    "batchsize = int (np.ceil(X_train_norm.shape[0]/batches))\n",
    "cnn.FTrain(epochs,\\\n",
    "           batchsize,\\\n",
    "           X_train_norm,\\\n",
    "           y_train_ohe,\\\n",
    "           X_test_norm,\\\n",
    "           y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n",
      "Prediction: 7\n",
      "\n",
      "Image: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n",
      "Prediction: 9\n",
      "\n",
      "Image: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n",
      "Prediction: 0\n",
      "\n",
      "Image: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n",
      "Prediction: 2\n",
      "\n",
      "Image: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n",
      "Prediction: 7\n",
      "\n",
      "Image: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "Prediction: 7\n",
      "\n",
      "Image: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAC91JREFUeJzt3d+LXPUdxvHncZNoqjGRakWNuBZKQIRmg4SKItuESKySeNGLBBQjLelFK4YWRHvT5B8Qe1GEEE0EY0SjcYu01oBZRGi1SVxrzI+iYcUEdRUNUS8aknx6MSeyDal7dtnvN7P7eb9gyOzumXm+s5tnzjkzZ87XESEAuVxwvgcAoD6KDyRE8YGEKD6QEMUHEqL4QEJdUXzby20fsv2+7YcLZz1pe8T2vpI5o/Kutb3L9n7b79l+sHDeRbbfsv1Ok7ehZF6T2WP7bdsvl85q8oZtv2t7yPbuwlnzbG+3fdD2Ads3F8xa0DymM5fjttcVCYuI83qR1CPpA0k/lDRL0juSbiiYd5ukRZL2VXp8V0la1FyfI+nfhR+fJV3SXJ8p6U1JPyn8GH8r6RlJL1f6nQ5LurxS1lOSftlcnyVpXqXcHkmfSLquxP13wxp/saT3I+JwRJyQ9KyklaXCIuJ1SV+Uuv9z5H0cEXub619JOiDpmoJ5ERFfN1/ObC7FjtKyPV/SnZI2lco4X2zPVWdF8YQkRcSJiDhWKX6ppA8i4sMSd94Nxb9G0kejvj6igsU4n2z3SupTZy1cMqfH9pCkEUk7I6Jk3mOSHpJ0umDG2ULSq7b32F5bMOd6SZ9J2tzsymyyfXHBvNFWSdpW6s67ofgp2L5E0guS1kXE8ZJZEXEqIhZKmi9pse0bS+TYvkvSSETsKXH/3+HWiFgk6Q5Jv7Z9W6GcGersFj4eEX2SvpFU9DUoSbI9S9IKSc+XyuiG4h+VdO2or+c335s2bM9Up/RbI+LFWrnNZukuScsLRdwiaYXtYXV20ZbYfrpQ1rci4mjz74ikHersLpZwRNKRUVtM29V5IijtDkl7I+LTUgHdUPx/SvqR7eubZ7pVkv58nsc0aWxbnX3EAxHxaIW8K2zPa67PlrRM0sESWRHxSETMj4hedf5ur0XEPSWyzrB9se05Z65Lul1SkXdoIuITSR/ZXtB8a6mk/SWyzrJaBTfzpc6mzHkVESdt/0bS39R5JfPJiHivVJ7tbZL6JV1u+4ikP0TEE6Xy1Fkr3ivp3Wa/W5J+HxF/KZR3laSnbPeo88T+XERUeZutkisl7eg8n2qGpGci4pWCeQ9I2tqslA5Lur9g1pkns2WSflU0p3nrAEAi3bCpD6Ayig8kRPGBhCg+kBDFBxLqquIXPvzyvGWRR1635XVV8SXV/OVW/UOSR1435XVb8QFUUOQAHtvT+qig2bNnj/s2J0+e1IwZEztQ8uqrrx73bY4fP65LL710QnkXXnjhuG/z5Zdf6rLLLptQ3qFDh8Z9m9OnT+uCCya23jp16tSEbjdVRITHWua8H7I7FS1YsGDshSbR+vXrq+b19vZWzevv76+ad+xYrY/Udy829YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJNSq+DWnuAJQ3pjFb07a+Cd1Tvl7g6TVtm8oPTAA5bRZ41ed4gpAeW2Kn2aKKyCLSfuQTnPigNqfWQYwAW2K32qKq4jYKGmjNP0/lgtMdW029af1FFdARmOu8WtPcQWgvFb7+M08b6XmegNQGUfuAQlRfCAhig8kRPGBhCg+kBDFBxKi+EBCFB9IaFrMpLNmzZqqeZs3b66aNzAwUDWvtrvvvrtq3pYtW6rmdSPW+EBCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iozRRaT9oesb2vxoAAlNdmjb9F0vLC4wBQ0ZjFj4jXJX1RYSwAKmEfH0iIufOAhCat+MydB0wdbOoDCbV5O2+bpL9LWmD7iO1flB8WgJLaTJq5usZAANTDpj6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYSKzJ3X09OjOXPmlLjrc6o9l92GDRuq5q1fv75q3ksvvVQ1b3h4uGoeWOMDKVF8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgoTYn27zW9i7b+22/Z/vBGgMDUE6bY/VPSvpdROy1PUfSHts7I2J/4bEBKKTN3HkfR8Te5vpXkg5Iuqb0wACUM659fNu9kvokvVliMADqaP2xXNuXSHpB0rqIOH6On387d57tSRsggMnXqvi2Z6pT+q0R8eK5lhk9d96MGTOYOw/oYm1e1bekJyQdiIhHyw8JQGlt9vFvkXSvpCW2h5rLzwqPC0BBbebOe0MSO+3ANMKRe0BCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEnLE5B9Wb7vqsfr9/f0146obHBysmlfi/8R34UNdkysixvyFssYHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQm3OsnuR7bdsv9PMnbehxsAAlNPmvPr/kbQkIr5uzq//hu2/RsQ/Co8NQCFtzrIbkr5uvpzZXJgwA5jCWu3j2+6xPSRpRNLOiGDuPGAKa1X8iDgVEQslzZe02PaNZy9je63t3bZ3T/YgAUyucb2qHxHHJO2StPwcP9sYETdFxE2TNTgAZbR5Vf8K2/Oa67MlLZN0sPTAAJTT5lX9qyQ9ZbtHnSeK5yLi5bLDAlBSm1f1/yWpr8JYAFTCkXtAQhQfSIjiAwlRfCAhig8kRPGBhCg+kBDFBxJqc+Re16s9t1xtK1eurJo3MDBQNQ/1scYHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQq2L30yq8bZtTrQJTHHjWeM/KOlAqYEAqKftFFrzJd0paVPZ4QCooe0a/zFJD0k6XXAsACppM5POXZJGImLPGMsxdx4wRbRZ498iaYXtYUnPSlpi++mzF2LuPGDqGLP4EfFIRMyPiF5JqyS9FhH3FB8ZgGJ4Hx9IaFyn3oqIQUmDRUYCoBrW+EBCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEpoWc+dNd319fVXzhoeHq+ahPtb4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQhQfSKjVIbvNqbW/knRK0klOoQ1MbeM5Vv+nEfF5sZEAqIZNfSChtsUPSa/a3mN7bckBASiv7ab+rRFx1PYPJO20fTAiXh+9QPOEwJMCMAW0WuNHxNHm3xFJOyQtPscyzJ0HTBFtZsu92PacM9cl3S5pX+mBASinzab+lZJ22D6z/DMR8UrRUQEoasziR8RhST+uMBYAlfB2HpAQxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhJg7bwro7++vmjc0NFQ1r/bjmzt3btW8gYGBqnltsMYHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQq2Kb3ue7e22D9o+YPvm0gMDUE7bY/X/KOmViPi57VmSvldwTAAKG7P4tudKuk3SGkmKiBOSTpQdFoCS2mzqXy/pM0mbbb9te1Mzscb/sL3W9m7buyd9lAAmVZviz5C0SNLjEdEn6RtJD5+9EFNoAVNHm+IfkXQkIt5svt6uzhMBgClqzOJHxCeSPrK9oPnWUkn7i44KQFFtX9V/QNLW5hX9w5LuLzckAKW1Kn5EDEli3x2YJjhyD0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQsydNwHz5s2rmtfb21s1r/bjW7hw4bTOu++++6plDQ4OtlqONT6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpDQmMW3vcD20KjLcdvragwOQBljHrIbEYckLZQk2z2SjkraUXhcAAoa76b+UkkfRMSHJQYDoI7xFn+VpG0lBgKgntbFb86pv0LS8//n58ydB0wR4/lY7h2S9kbEp+f6YURslLRRkmzHJIwNQCHj2dRfLTbzgWmhVfGbabGXSXqx7HAA1NB2Cq1vJH2/8FgAVMKRe0BCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEKOmPzP09j+TNJEPrN/uaTPJ3k43ZBFHnm18q6LiCvGWqhI8SfK9u6IuGm6ZZFHXrflsakPJETxgYS6rfgbp2kWeeR1VV5X7eMDqKPb1vgAKqD4QEIUH0iI4gMJUXwgof8CcUuHi68HMwAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n",
      "Prediction: 5\n",
      "\n",
      "Image: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n",
      "Prediction: 0\n",
      "\n",
      "Image: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n",
      "Prediction: 5\n",
      "\n",
      "Image: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n",
      "Prediction: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def plot_digit(feature_vector):\n",
    "    dim = int(np.sqrt(len(feature_vector)))\n",
    "    plt.gray()\n",
    "    plt.matshow(feature_vector.reshape(dim,dim))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_test(index1,index2,clearn_,Xp,Xt,y):\n",
    "    for index in range(index1,index2):\n",
    "        print('Image:',index)\n",
    "        plot_digit(Xp[index])\n",
    "        ypred = clearn_.FPredict(Xt[index].reshape(1,-1))\n",
    "        print('Label:', int(y[index]))\n",
    "        print('Prediction:',int(ypred))\n",
    "        print('')\n",
    "        \n",
    "plot_test(0,10,cnn,X_test,X_test_norm,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X\n",
      " [[[[-16. -15. -14. -13.]\n",
      "   [-12. -11. -10.  -9.]\n",
      "   [ -8.  -7.  -6.  -5.]\n",
      "   [ -4.  -3.  -2.  -1.]]]\n",
      "\n",
      "\n",
      " [[[  0.   1.   2.   3.]\n",
      "   [  4.  10.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]]]\n",
      "\n",
      "y\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "yhat\n",
      " [[ 0.  1. -1.]\n",
      " [ 0.  1. -1.]]\n",
      "\n",
      "Filter Information:\n",
      "  tag: convolution\n",
      "  num_filt: 2\n",
      "  num_ch: 1\n",
      "  f_i: 2\n",
      "  f_j: 2\n",
      "  stride_i: 1\n",
      "  stride_j: 1\n",
      "  filt:\n",
      " [[[[0 1]\n",
      "   [2 3]]]\n",
      "\n",
      "\n",
      " [[[4 5]\n",
      "   [6 7]]]]\n",
      "  bias:\n",
      " [[0 1]]\n",
      "None\n",
      "z [[[[ -72.  -66.  -60.]\n",
      "   [ -48.  -42.  -36.]\n",
      "   [ -24.  -18.  -12.]]\n",
      "\n",
      "  [[-287. -265. -243.]\n",
      "   [-199. -177. -155.]\n",
      "   [-111.  -89.  -67.]]]\n",
      "\n",
      "\n",
      " [[[  39.   40.   36.]\n",
      "   [  53.   54.   60.]\n",
      "   [  72.   78.   84.]]\n",
      "\n",
      "  [[ 100.  117.  109.]\n",
      "   [ 178.  195.  197.]\n",
      "   [ 241.  263.  285.]]]]\n",
      "f [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 39.  40.  36.]\n",
      "   [ 53.  54.  60.]\n",
      "   [ 72.  78.  84.]]\n",
      "\n",
      "  [[100. 117. 109.]\n",
      "   [178. 195. 197.]\n",
      "   [241. 263. 285.]]]]\n",
      "\n",
      "Pool Information:\n",
      "  tag: pool\n",
      "  pool_i: 2\n",
      "  pool_j: 2\n",
      "  stide_i: 2\n",
      "  stride_j: 2\n",
      "None\n",
      "z [[[[  0.   0.]\n",
      "   [  0.   0.]]\n",
      "\n",
      "  [[  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 54.  60.]\n",
      "   [ 78.  84.]]\n",
      "\n",
      "  [[195. 197.]\n",
      "   [263. 285.]]]]\n",
      "f [[[[  0.   0.]\n",
      "   [  0.   0.]]\n",
      "\n",
      "  [[  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 54.  60.]\n",
      "   [ 78.  84.]]\n",
      "\n",
      "  [[195. 197.]\n",
      "   [263. 285.]]]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 8\n",
      "  neurons_out: 2\n",
      "  weights:\n",
      " [[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]\n",
      " [ 6.  7.]\n",
      " [ 8.  9.]\n",
      " [10. 11.]\n",
      " [12. 13.]\n",
      " [14. 15.]]\n",
      "  bias:\n",
      " [[0. 1.]]\n",
      "None\n",
      "z [[0.0000e+00 1.0000e+00]\n",
      " [1.1612e+04 1.2829e+04]]\n",
      "f [[0.0000e+00 1.0000e+00]\n",
      " [1.1612e+04 1.2829e+04]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 2\n",
      "  neurons_out: 3\n",
      "  weights:\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "  bias:\n",
      " [[0. 1. 2.]]\n",
      "None\n",
      "z [[3.0000e+00 5.0000e+00 7.0000e+00]\n",
      " [3.8487e+04 6.2929e+04 8.7371e+04]]\n",
      "f [[3.0000e+00 5.0000e+00 7.0000e+00]\n",
      " [3.8487e+04 6.2929e+04 8.7371e+04]]\n",
      "\n",
      "y\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "yhat\n",
      " [[ 0.  1. -1.]\n",
      " [ 0.  1. -1.]]\n",
      "y-yhat\n",
      " [[0. 0. 3.]\n",
      " [3. 3. 6.]]\n",
      "\n",
      "dout\n",
      " [[-0. -2.  3.]\n",
      " [-0. -5.  6.]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 2\n",
      "  neurons_out: 3\n",
      "  weights:\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "  bias:\n",
      " [[0. 1. 2.]]\n",
      "dprev\n",
      " [[-0. -2.  3.]\n",
      " [-0. -5.  6.]]\n",
      "f(data)\n",
      " [[0.0000e+00 1.0000e+00]\n",
      " [1.1612e+04 1.2829e+04]]\n",
      "d(data)\n",
      " [[0. 1.]\n",
      " [1. 1.]]\n",
      "weight\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]]\n",
      "bias\n",
      " [[0. 1. 2.]]\n",
      "dW\n",
      " [[     0. -58060.  69672.]\n",
      " [     0. -64147.  76977.]]\n",
      "db\n",
      " [[ 0. -7.  9.]]\n",
      "dout\n",
      " [[ 0.  7.]\n",
      " [ 7. 10.]]\n",
      "\n",
      "Connection Information:\n",
      "  tag: connection\n",
      "  neurons_in: 8\n",
      "  neurons_out: 2\n",
      "  weights:\n",
      " [[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]\n",
      " [ 6.  7.]\n",
      " [ 8.  9.]\n",
      " [10. 11.]\n",
      " [12. 13.]\n",
      " [14. 15.]]\n",
      "  bias:\n",
      " [[0. 1.]]\n",
      "dprev\n",
      " [[ 0.  7.]\n",
      " [ 7. 10.]]\n",
      "f(data)\n",
      " [[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 54.  60.  78.  84. 195. 197. 263. 285.]]\n",
      "d(data)\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "weight\n",
      " [[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]\n",
      " [ 6.  7.]\n",
      " [ 8.  9.]\n",
      " [10. 11.]\n",
      " [12. 13.]\n",
      " [14. 15.]]\n",
      "bias\n",
      " [[0. 1.]]\n",
      "dW\n",
      " [[ 378.  540.]\n",
      " [ 420.  600.]\n",
      " [ 546.  780.]\n",
      " [ 588.  840.]\n",
      " [1365. 1950.]\n",
      " [1379. 1970.]\n",
      " [1841. 2630.]\n",
      " [1995. 2850.]]\n",
      "db\n",
      " [[ 7. 17.]]\n",
      "dout\n",
      " [[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 10.  44.  78. 112. 146. 180. 214. 248.]]\n",
      "\n",
      "Pool Information:\n",
      "  tag: pool\n",
      "  pool_i: 2\n",
      "  pool_j: 2\n",
      "  stide_i: 2\n",
      "  stride_j: 2\n",
      "dprev\n",
      " [[[[  0.   0.]\n",
      "   [  0.   0.]]\n",
      "\n",
      "  [[  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 10.  44.]\n",
      "   [ 78. 112.]]\n",
      "\n",
      "  [[146. 180.]\n",
      "   [214. 248.]]]]\n",
      "imag_in\n",
      " [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 39.  40.  36.]\n",
      "   [ 53.  54.  60.]\n",
      "   [ 72.  78.  84.]]\n",
      "\n",
      "  [[100. 117. 109.]\n",
      "   [178. 195. 197.]\n",
      "   [241. 263. 285.]]]]\n",
      "dout\n",
      " [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.   0.]\n",
      "   [  0.  10.  44.]\n",
      "   [  0.  78. 112.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0. 146. 180.]\n",
      "   [  0. 214. 248.]]]]\n",
      "\n",
      "Filter Information:\n",
      "  tag: convolution\n",
      "  num_filt: 2\n",
      "  num_ch: 1\n",
      "  f_i: 2\n",
      "  f_j: 2\n",
      "  stride_i: 1\n",
      "  stride_j: 1\n",
      "  filt:\n",
      " [[[[0 1]\n",
      "   [2 3]]]\n",
      "\n",
      "\n",
      " [[[4 5]\n",
      "   [6 7]]]]\n",
      "  bias:\n",
      " [[0 1]]\n",
      "dprev\n",
      " [[[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.   0.]\n",
      "   [  0.  10.  44.]\n",
      "   [  0.  78. 112.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0. 146. 180.]\n",
      "   [  0. 214. 248.]]]]\n",
      "imag_in\n",
      " [[[[-16. -15. -14. -13.]\n",
      "   [-12. -11. -10.  -9.]\n",
      "   [ -8.  -7.  -6.  -5.]\n",
      "   [ -4.  -3.  -2.  -1.]]]\n",
      "\n",
      "\n",
      " [[[  0.   1.   2.   3.]\n",
      "   [  4.  10.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]]]\n",
      "dfilt\n",
      " [[[[ 2186.  2380.]\n",
      "   [ 3112.  3356.]]]\n",
      "\n",
      "\n",
      " [[[ 6946.  7004.]\n",
      "   [ 9368. 10156.]]]]\n",
      "dbias\n",
      " [[244. 788.]]\n",
      "dout\n",
      " [[[[   0.    0.    0.    0.]\n",
      "   [   0.    0.    0.    0.]\n",
      "   [   0.    0.    0.    0.]\n",
      "   [   0.    0.    0.    0.]]]\n",
      "\n",
      "\n",
      " [[[   0.    0.    0.    0.]\n",
      "   [   0.  584. 1460.  944.]\n",
      "   [   0. 1752. 4360. 2744.]\n",
      "   [   0. 1440. 3444. 2072.]]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filt_info = CInfo([2,-1,2,2])\n",
    "filt = CLayer('convolution',filt_info)\n",
    "\n",
    "pool_info = CInfo([-1,2,2],2,2)\n",
    "pool = CLayer('pool',pool_info)\n",
    "\n",
    "conn_info = CInfo([-1,2])\n",
    "conn = CLayer('connection',conn_info)\n",
    "\n",
    "cnn = CNN([1,4,4],3,[filt,pool,conn],1,1)\n",
    "\n",
    "cnn.layer[0].weight = np.arange(8).reshape(2,1,2,2)\n",
    "cnn.layer[0].bias = np.arange(2).reshape(1,2)\n",
    "cnn.layer[2].weight = np.arange(16).reshape(8,2).astype(float)\n",
    "cnn.layer[2].bias = np.arange(2).reshape(1,2).astype(float)\n",
    "cnn.layer[3].weight = np.arange(6).reshape(2,3).astype(float)\n",
    "cnn.layer[3].bias = np.arange(3).reshape(1,3).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "X = np.arange(-16,16).reshape(2,1,4,4).astype(float)\n",
    "X[1,0,1,1] = 10\n",
    "y = np.arange(6).reshape(2,3).astype(float)\n",
    "yhat = np.zeros(6).reshape(2,3).astype(float)\n",
    "yhat[0][1] = 1\n",
    "yhat[0][2] = -1\n",
    "yhat[1][1] = 1\n",
    "yhat[1][2] = -1\n",
    "\n",
    "print('')\n",
    "print('X\\n',X)\n",
    "print('')\n",
    "print('y\\n',y)\n",
    "print('yhat\\n',yhat)\n",
    "cnn.FFeedForward(X)\n",
    "print('')\n",
    "print('y\\n',y)\n",
    "print('yhat\\n',yhat)\n",
    "print('y-yhat\\n',y-yhat)\n",
    "print('')\n",
    "cnn.FBackPropagation(y,yhat)\n",
    "#cnn.FPrint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\ndef InitializeFilter(dimensions):\\n    return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(dimensions))),size=dimensions)\\n\\n\\ndef Convolution(images, filt, bias, activat, stride_i=1,stride_j=1):\\n    (num_filt, num_ch_f, f_i, f_j) = filt.shape\\n    (num_imag, num_ch, imag_i, imag_j) = images.shape\\n    \\n    if(num_ch_f != num_ch):\\n        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\\n\\n    out_i = int(np.ceil((imag_i - f_i)/stride_i) + 1)\\n    out_j = int(np.ceil((imag_j - f_j)/stride_j) + 1)\\n    z = np.zeros((num_imag, num_filt, out_i, out_j))\\n    i=0\\n    for image in images:\\n        for curr_f in range(num_filt):\\n            curr_y = curr_y_end = out_y = 0\\n            f_y_end = f_j + 1\\n            while(out_y < out_j):\\n                curr_x = curr_x_end = out_x = 0\\n                curr_y_end = curr_y + f_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                    f_y_end = curr_y_end - curr_y\\n                f_x_end = f_i + 1\\n                while(out_x < out_i):\\n                    curr_x_end = curr_x + f_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                        f_x_end = curr_x_end - curr_x\\n                    z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + bias[curr_f]\\n                    curr_x += stride_i\\n                    out_x += 1\\n                curr_y += stride_j\\n                out_y += 1\\n        i+=1\\n    return z,activat(z)\\n\\ndef FMaxPool(images,pool_i=2,pool_j=2,stride_i=2,stride_j=2):\\n    (num_imag, num_ch, imag_i, imag_j) = images.shape\\n\\n    out_i = int(np.ceil((imag_i - pool_i)/stride_i)) + 1\\n    out_j = int(np.ceil((imag_j - pool_j)/stride_j)) + 1\\n    z = np.zeros((num_imag, num_ch, out_i, out_j))\\n    index = np.zeros((num_imag, num_ch, out_i, out_j))\\n    \\n    i=0\\n    for image in images:\\n        for curr_chan in range(num_ch):\\n            curr_y = out_y = 0\\n            while(out_y < out_j):\\n                curr_x = out_x = 0\\n                curr_y_end = curr_y + pool_j\\n                if(curr_y_end > imag_j):\\n                    current_y_end = imag_j\\n                while(out_x < out_i):\\n                    curr_x_end = curr_x + pool_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                    z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\\n                    index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\\n                    curr_x += stride_i\\n                    out_x +=1\\n                curr_y += stride_j\\n                out_y += 1\\n        i+=1\\n    return z,index\\n\\ndef FConnection(images,weights,bias,activation):\\n    z = images.dot(weights) + bias\\n    return z, activation(z)\\n\\ndef FbackConvolution(dprev,conv_in,filt,derivative,stride_i=1,stride_j=1):\\n    (num_filt, num_ch_f, f_i, f_j) = filt.shape\\n    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\\n    \\n    if(num_ch_f != num_ch):\\n        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\\n\\n    dout = np.zeros((num_ch,imag_i,imag_j))\\n    dfilt = np.zeros(filt.shape)\\n    dbias = np.zeros((num_filt,1))\\n    \\n    for conv in conv_in:\\n        dout_conv = np.zeros((num_ch,imag_i,imag_j))\\n        for curr_f in range(num_filt):\\n            curr_y = out_y = 0\\n            f_y_end = f_i\\n            while(curr_y + f_j < imag_j + 1):\\n                curr_x = out_x = 0\\n                curr_y_end = curr_y + f_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                    f_y_end = curr_y_end - curr_y\\n                f_x_end = f_j\\n                while(curr_x + f_i < imag_i + 1): \\n                    curr_x_end = curr_x + f_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                        f_x_end = curr_x_end - curr_i\\n                    dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\\n                    dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\\n\\n                    curr_x += stride_i\\n                    out_x +=1\\n                curr_y += stride_j\\n                out_y += 1\\n            dbias[curr_f] = np.sum(dprev[curr_f])\\n        dout += dout_conv*derivative(conv)\\n\\n    return dout,dfilt,dbias\\n\\ndef FbackMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2):\\n    (num_ch_p, dp_i, dp_j) = dpool.shape\\n    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\\n    \\n    if(num_ch_p != num_ch):\\n        print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\\n\\n    dout = np.zeros((num_ch,imag_i,imag_j))\\n    \\n    for conv in conv_in:\\n        for curr_ch in range(num_ch):\\n            curr_y = curr_y_end = out_y = 0\\n            while(out_y < dp_j):\\n                curr_x = curr_x_end = out_x = 0\\n                curr_y_end = curr_y + p_j\\n                if(curr_y_end > imag_j):\\n                    curr_y_end = imag_j\\n                while(out_x < dp_i):\\n                    curr_x_end = curr_x + p_i\\n                    if(curr_x_end > imag_i):\\n                        curr_x_end = imag_i\\n                    (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\\n                    dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\\n\\n                    curr_x += stride_i\\n                    out_x += 1\\n                curr_y += stride_j\\n                out_y += 1\\n    return dout\\n\\ndef FbackConnection(dprev,data_in,weight,activation,derivative):\\n    dW = activation(data_in).T.dot(dprev)\\n    db = np.sum(dprev,axis=0,keepdims=True)\\n    dout = dprev.dot(weight.T)*derivative(data_in)\\n    return dout, dW, db\\n    \\n#def Convolution(images, filt, bias, activation, stride_i=1,stride_j=1):\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "def InitializeFilter(dimensions):\n",
    "    return np.random.normal(loc=0,scale=1.0/(np.sqrt(np.prod(dimensions))),size=dimensions)\n",
    "\n",
    "\n",
    "def Convolution(images, filt, bias, activat, stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the images!\")\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - f_i)/stride_i) + 1)\n",
    "    out_j = int(np.ceil((imag_j - f_j)/stride_j) + 1)\n",
    "    z = np.zeros((num_imag, num_filt, out_i, out_j))\n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            f_y_end = f_j + 1\n",
    "            while(out_y < out_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_i + 1\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_x\n",
    "                    z[i,curr_f,out_x,out_y] = np.sum(image[:,curr_x:curr_x_end,curr_y:curr_y_end]*filt[curr_f,:,0:f_x_end,0:f_y_end]) + bias[curr_f]\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,activat(z)\n",
    "\n",
    "def FMaxPool(images,pool_i=2,pool_j=2,stride_i=2,stride_j=2):\n",
    "    (num_imag, num_ch, imag_i, imag_j) = images.shape\n",
    "\n",
    "    out_i = int(np.ceil((imag_i - pool_i)/stride_i)) + 1\n",
    "    out_j = int(np.ceil((imag_j - pool_j)/stride_j)) + 1\n",
    "    z = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    index = np.zeros((num_imag, num_ch, out_i, out_j))\n",
    "    \n",
    "    i=0\n",
    "    for image in images:\n",
    "        for curr_chan in range(num_ch):\n",
    "            curr_y = out_y = 0\n",
    "            while(out_y < out_j):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + pool_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    current_y_end = imag_j\n",
    "                while(out_x < out_i):\n",
    "                    curr_x_end = curr_x + pool_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    z[i,curr_chan,out_x,out_y] = np.max(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    index[i,curr_chan,out_x,out_y] = np.argmax(image[curr_chan,curr_x:curr_x_end,curr_y:curr_y_end])\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "        i+=1\n",
    "    return z,index\n",
    "\n",
    "def FConnection(images,weights,bias,activation):\n",
    "    z = images.dot(weights) + bias\n",
    "    return z, activation(z)\n",
    "\n",
    "def FbackConvolution(dprev,conv_in,filt,derivative,stride_i=1,stride_j=1):\n",
    "    (num_filt, num_ch_f, f_i, f_j) = filt.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_f != num_ch):\n",
    "        print(\"Big mistake! The number of channels in the filter does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dbias = np.zeros((num_filt,1))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        dout_conv = np.zeros((num_ch,imag_i,imag_j))\n",
    "        for curr_f in range(num_filt):\n",
    "            curr_y = out_y = 0\n",
    "            f_y_end = f_i\n",
    "            while(curr_y + f_j < imag_j + 1):\n",
    "                curr_x = out_x = 0\n",
    "                curr_y_end = curr_y + f_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                    f_y_end = curr_y_end - curr_y\n",
    "                f_x_end = f_j\n",
    "                while(curr_x + f_i < imag_i + 1): \n",
    "                    curr_x_end = curr_x + f_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                        f_x_end = curr_x_end - curr_i\n",
    "                    dout_conv[:,curr_x:curr_x_end,curr_y:curr_y_end] += dprev[curr_f, out_x, out_y] * filt[curr_f,:,:f_x_end,:f_y_end]\n",
    "                    dfilt[curr_f,:,:f_x_end,:f_y_end] += dprev[curr_f,out_x,out_y] * conv[:,curr_x:curr_x_end,curr_y:curr_y_end]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x +=1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "            dbias[curr_f] = np.sum(dprev[curr_f])\n",
    "        dout += dout_conv*derivative(conv)\n",
    "\n",
    "    return dout,dfilt,dbias\n",
    "\n",
    "def FbackMaxPool(dpool, conv_in, p_i=2, p_j=2, stride_i=2, stride_j=2):\n",
    "    (num_ch_p, dp_i, dp_j) = dpool.shape\n",
    "    (num_imag, num_ch, imag_i, imag_j) = conv_in.shape\n",
    "    \n",
    "    if(num_ch_p != num_ch):\n",
    "        print(\"Big mistake! The number of channels in dpool does not match the number of channels in the input!\")\n",
    "\n",
    "    dout = np.zeros((num_ch,imag_i,imag_j))\n",
    "    \n",
    "    for conv in conv_in:\n",
    "        for curr_ch in range(num_ch):\n",
    "            curr_y = curr_y_end = out_y = 0\n",
    "            while(out_y < dp_j):\n",
    "                curr_x = curr_x_end = out_x = 0\n",
    "                curr_y_end = curr_y + p_j\n",
    "                if(curr_y_end > imag_j):\n",
    "                    curr_y_end = imag_j\n",
    "                while(out_x < dp_i):\n",
    "                    curr_x_end = curr_x + p_i\n",
    "                    if(curr_x_end > imag_i):\n",
    "                        curr_x_end = imag_i\n",
    "                    (a,b) = np.unravel_index(np.nanargmax(conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end]),conv[curr_ch,curr_x:curr_x_end,curr_y:curr_y_end].shape)\n",
    "                    dout[curr_ch,curr_x+a,curr_y+b] += dpool[curr_ch,out_x,out_y]\n",
    "\n",
    "                    curr_x += stride_i\n",
    "                    out_x += 1\n",
    "                curr_y += stride_j\n",
    "                out_y += 1\n",
    "    return dout\n",
    "\n",
    "def FbackConnection(dprev,data_in,weight,activation,derivative):\n",
    "    dW = activation(data_in).T.dot(dprev)\n",
    "    db = np.sum(dprev,axis=0,keepdims=True)\n",
    "    dout = dprev.dot(weight.T)*derivative(data_in)\n",
    "    return dout, dW, db\n",
    "    \n",
    "#def Convolution(images, filt, bias, activation, stride_i=1,stride_j=1):\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
